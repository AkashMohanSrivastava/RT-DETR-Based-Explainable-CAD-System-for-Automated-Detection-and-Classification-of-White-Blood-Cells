{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RT-DETR-L Training\n",
    "\n",
    "Training RT-DETR-L with ResNet-50 backbone for WBC Classification on Raabin-WBC dataset.\n",
    "\n",
    "## Model Details\n",
    "- **Backbone**: ResNet-50\n",
    "- **Training**: Pretrained weights (fine-tuning)\n",
    "- **Dataset**: Raabin-WBC with 5 cell types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U ultralytics torch torchvision pillow tqdm scikit-learn seaborn timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import yaml\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ultralytics import RTDETR\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\n",
      "Base directory: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\n",
      "Data root: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\n",
      "\n",
      "Using device: cuda\n",
      "Dataset mode: FULL DATASET\n",
      "\n",
      "Training data: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\Train\\images\n",
      "Validation data: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\val\\images\n",
      "\n",
      "Model: RT-DETR-L (ResNet-50)\n",
      "Training mode: Pretrained (fine-tuning)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MODEL CONFIGURATION\n",
    "# =============================================================================\n",
    "MODEL_NAME = \"RT-DETR-L\"\n",
    "BACKBONE = \"ResNet-50\"\n",
    "IS_PRETRAINED = True  # Using pretrained weights\n",
    "\n",
    "# Pretrained model file\n",
    "MODEL_FILE = \"rtdetr-l.pt\"\n",
    "\n",
    "# =============================================================================\n",
    "# BASE DIRECTORY\n",
    "# =============================================================================\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "BASE_DIR = os.path.join(NOTEBOOK_DIR, \"output\")\n",
    "\n",
    "# Dataset path (contains separate Train and val folders)\n",
    "DATA_ROOT = r\"C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\"\n",
    "\n",
    "print(f\"Notebook directory: {NOTEBOOK_DIR}\")\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SAMPLING CONFIGURATION\n",
    "# =============================================================================\n",
    "USE_FULL_DATASET = True  # Set to True to use ALL images, False for sampling\n",
    "\n",
    "# Sample sizes per class (only used when USE_FULL_DATASET=False)\n",
    "TRAIN_SAMPLE_SIZE = 100   # Number of training samples per class\n",
    "VAL_SAMPLE_SIZE = 20      # Number of validation samples per class\n",
    "\n",
    "# Data paths (separate train and validation directories)\n",
    "TRAIN_IMAGES_DIR = os.path.join(DATA_ROOT, \"Train\", \"images\")\n",
    "TRAIN_LABELS_DIR = os.path.join(DATA_ROOT, \"Train\", \"labels\")\n",
    "VAL_IMAGES_DIR = os.path.join(DATA_ROOT, \"val\", \"images\")\n",
    "VAL_LABELS_DIR = os.path.join(DATA_ROOT, \"val\", \"labels\")\n",
    "\n",
    "# For evaluation (uses training images by default)\n",
    "IMAGES_DIR = TRAIN_IMAGES_DIR\n",
    "\n",
    "# Output directories\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"results\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Class definitions\n",
    "CLASSES = {\n",
    "    \"Basophil\": 0,\n",
    "    \"Eosinophil\": 1,\n",
    "    \"Lymphocyte\": 2,\n",
    "    \"Monocyte\": 3,\n",
    "    \"Neutrophil\": 4\n",
    "}\n",
    "ID2LABEL = {v: k for k, v in CLASSES.items()}\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "print(f\"\\nUsing device: {DEVICE}\")\n",
    "if USE_FULL_DATASET:\n",
    "    print(f\"Dataset mode: FULL DATASET\")\n",
    "else:\n",
    "    print(f\"Dataset mode: SAMPLED (Train: {TRAIN_SAMPLE_SIZE}/class, Val: {VAL_SAMPLE_SIZE}/class)\")\n",
    "print(f\"\\nTraining data: {TRAIN_IMAGES_DIR}\")\n",
    "print(f\"Validation data: {VAL_IMAGES_DIR}\")\n",
    "print(f\"\\nModel: {MODEL_NAME} ({BACKBONE})\")\n",
    "print(f\"Training mode: {'Pretrained (fine-tuning)' if IS_PRETRAINED else 'From scratch'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration (Pretrained Fine-tuning):\n",
      "============================================================\n",
      "  epochs: 3\n",
      "  imgsz: 640\n",
      "  batch: 4\n",
      "  lr0: 0.01\n",
      "  lrf: 0.0001\n",
      "  momentum: 0.937\n",
      "  weight_decay: 0.0005\n",
      "  workers: 8\n",
      "  patience: 15\n",
      "  cos_lr: True\n",
      "  warmup_epochs: 1\n",
      "  warmup_momentum: 0.8\n",
      "  warmup_bias_lr: 0.1\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TRAINING HYPERPARAMETERS (PRETRAINED CONFIG)\n",
    "# =============================================================================\n",
    "# Fewer epochs needed since backbone is already trained\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    \"epochs\": 3,            \n",
    "    \"imgsz\": 640,\n",
    "    \"batch\": 4,\n",
    "    \"lr0\": 0.01,            \n",
    "    \"lrf\": 0.0001,\n",
    "    \"momentum\": 0.937,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"workers\": 8,\n",
    "    \"patience\": 15,\n",
    "    \"cos_lr\": True,\n",
    "    \"warmup_epochs\": 1,\n",
    "    \"warmup_momentum\": 0.8,\n",
    "    \"warmup_bias_lr\": 0.1,\n",
    "}\n",
    "\n",
    "print(\"Training Configuration (Pretrained Fine-tuning):\")\n",
    "print(\"=\"*60)\n",
    "for k, v in TRAINING_CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sampled_dataset(data_root, base_dir, classes, train_samples_per_class, val_samples_per_class, random_seed=42):\n",
    "    \"\"\"\n",
    "    Create a sampled dataset from separate Train and val directories.\n",
    "    - Samples from Train directory for training data\n",
    "    - Samples from val directory for validation data (NOT from Train)\n",
    "    - Creates train.txt/val.txt pointing to original images\n",
    "    - Corrects class IDs in label files if needed\n",
    "    \"\"\"\n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "    \n",
    "    # Define paths\n",
    "    subset_dir = os.path.join(base_dir, \"data_subset\")\n",
    "    \n",
    "    # Source paths - separate Train and val directories\n",
    "    src_train_images = os.path.join(data_root, \"Train\", \"images\")\n",
    "    src_train_labels = os.path.join(data_root, \"Train\", \"labels\")\n",
    "    src_val_images = os.path.join(data_root, \"val\", \"images\")\n",
    "    src_val_labels = os.path.join(data_root, \"val\", \"labels\")\n",
    "    \n",
    "    # Clean up existing subset directory\n",
    "    if os.path.exists(subset_dir):\n",
    "        shutil.rmtree(subset_dir)\n",
    "    os.makedirs(subset_dir, exist_ok=True)\n",
    "    \n",
    "    # Lists to store image paths\n",
    "    train_image_paths = []\n",
    "    val_image_paths = []\n",
    "    labels_corrected = 0\n",
    "    \n",
    "    total_train = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    print(\"Sampling from TRAINING dataset:\")\n",
    "    for cls_name, cls_id in classes.items():\n",
    "        # --- Training data (from Train directory) ---\n",
    "        src_cls_images = os.path.join(src_train_images, cls_name)\n",
    "        src_cls_labels = os.path.join(src_train_labels, cls_name)\n",
    "        \n",
    "        if os.path.exists(src_cls_images):\n",
    "            image_files = [f for f in os.listdir(src_cls_images) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            # Sample training images\n",
    "            if len(image_files) > train_samples_per_class:\n",
    "                image_files = random.sample(image_files, train_samples_per_class)\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                base_name = os.path.splitext(img_file)[0]\n",
    "                original_img_path = os.path.join(src_cls_images, img_file)\n",
    "                train_image_paths.append(original_img_path)\n",
    "                \n",
    "                # Correct label file if needed\n",
    "                label_file = base_name + \".txt\"\n",
    "                label_path = os.path.join(src_cls_labels, label_file)\n",
    "                \n",
    "                if os.path.exists(label_path):\n",
    "                    with open(label_path, 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                    \n",
    "                    new_lines = []\n",
    "                    needs_correction = False\n",
    "                    for line in lines:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) > 1:\n",
    "                            if parts[0] != str(cls_id):\n",
    "                                needs_correction = True\n",
    "                                parts[0] = str(cls_id)\n",
    "                            new_lines.append(' '.join(parts) + '\\n')\n",
    "                    \n",
    "                    if needs_correction:\n",
    "                        with open(label_path, 'w') as f:\n",
    "                            f.writelines(new_lines)\n",
    "                        labels_corrected += 1\n",
    "            \n",
    "            total_train += len(image_files)\n",
    "            print(f\"  {cls_name}: {len(image_files)} images\")\n",
    "    \n",
    "    print(f\"\\nSampling from VALIDATION dataset:\")\n",
    "    for cls_name, cls_id in classes.items():\n",
    "        # --- Validation data (from val directory - NOT from Train) ---\n",
    "        src_cls_val_images = os.path.join(src_val_images, cls_name)\n",
    "        src_cls_val_labels = os.path.join(src_val_labels, cls_name)\n",
    "        \n",
    "        if os.path.exists(src_cls_val_images):\n",
    "            val_files = [f for f in os.listdir(src_cls_val_images) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            # Sample validation images\n",
    "            if len(val_files) > val_samples_per_class:\n",
    "                val_files = random.sample(val_files, val_samples_per_class)\n",
    "            \n",
    "            for img_file in val_files:\n",
    "                base_name = os.path.splitext(img_file)[0]\n",
    "                original_img_path = os.path.join(src_cls_val_images, img_file)\n",
    "                val_image_paths.append(original_img_path)\n",
    "                \n",
    "                # Correct label file if needed\n",
    "                label_file = base_name + \".txt\"\n",
    "                label_path = os.path.join(src_cls_val_labels, label_file)\n",
    "                \n",
    "                if os.path.exists(label_path):\n",
    "                    with open(label_path, 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                    \n",
    "                    new_lines = []\n",
    "                    needs_correction = False\n",
    "                    for line in lines:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) > 1:\n",
    "                            if parts[0] != str(cls_id):\n",
    "                                needs_correction = True\n",
    "                                parts[0] = str(cls_id)\n",
    "                            new_lines.append(' '.join(parts) + '\\n')\n",
    "                    \n",
    "                    if needs_correction:\n",
    "                        with open(label_path, 'w') as f:\n",
    "                            f.writelines(new_lines)\n",
    "                        labels_corrected += 1\n",
    "            \n",
    "            total_val += len(val_files)\n",
    "            print(f\"  {cls_name}: {len(val_files)} images\")\n",
    "    \n",
    "    # Write train.txt\n",
    "    train_txt_path = os.path.join(subset_dir, \"train.txt\")\n",
    "    with open(train_txt_path, 'w') as f:\n",
    "        for img_path in train_image_paths:\n",
    "            f.write(img_path + '\\n')\n",
    "    \n",
    "    # Write val.txt\n",
    "    val_txt_path = os.path.join(subset_dir, \"val.txt\")\n",
    "    with open(val_txt_path, 'w') as f:\n",
    "        for img_path in val_image_paths:\n",
    "            f.write(img_path + '\\n')\n",
    "    \n",
    "    # Create data.yaml\n",
    "    data_yaml_path = os.path.join(subset_dir, \"data.yaml\")\n",
    "    data_config = {\n",
    "        'path': data_root,\n",
    "        'train': train_txt_path,\n",
    "        'val': val_txt_path,\n",
    "        'nc': len(classes),\n",
    "        'names': {v: k for k, v in classes.items()}\n",
    "    }\n",
    "    \n",
    "    with open(data_yaml_path, 'w') as f:\n",
    "        yaml.dump(data_config, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Sampled dataset created:\")\n",
    "    print(f\"  Training images: {total_train} (from Train/)\")\n",
    "    print(f\"  Validation images: {total_val} (from val/)\")\n",
    "    print(f\"  Labels corrected: {labels_corrected}\")\n",
    "    print(f\"  Config: {data_yaml_path}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    return data_yaml_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FULL DATASET\n",
      "\n",
      "Training: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\Train\\images\n",
      "Validation: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\val\\images\n",
      "\n",
      "Data config: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\data_full.yaml\n"
     ]
    }
   ],
   "source": [
    "# Create data configuration\n",
    "if USE_FULL_DATASET:\n",
    "    # Use full dataset - point directly to original Train and val directories\n",
    "    print(\"Using FULL DATASET\\n\")\n",
    "    print(f\"Training: {TRAIN_IMAGES_DIR}\")\n",
    "    print(f\"Validation: {VAL_IMAGES_DIR}\")\n",
    "    \n",
    "    data_yaml_path = os.path.join(BASE_DIR, \"data_full.yaml\")\n",
    "    data_config = {\n",
    "        'path': DATA_ROOT,\n",
    "        'train': 'Train/images',\n",
    "        'val': 'val/images',\n",
    "        'nc': NUM_CLASSES,\n",
    "        'names': ID2LABEL\n",
    "    }\n",
    "    \n",
    "    with open(data_yaml_path, 'w') as f:\n",
    "        yaml.dump(data_config, f, default_flow_style=False)\n",
    "    \n",
    "    DATA_YAML = data_yaml_path\n",
    "    print(f\"\\nData config: {DATA_YAML}\")\n",
    "else:\n",
    "    # Create sampled subset from both Train and val directories\n",
    "    print(f\"Creating SAMPLED dataset...\")\n",
    "    print(f\"  Train samples: {TRAIN_SAMPLE_SIZE} per class\")\n",
    "    print(f\"  Val samples: {VAL_SAMPLE_SIZE} per class\\n\")\n",
    "    \n",
    "    DATA_YAML = create_sampled_dataset(\n",
    "        DATA_ROOT, \n",
    "        BASE_DIR, \n",
    "        CLASSES, \n",
    "        train_samples_per_class=TRAIN_SAMPLE_SIZE,\n",
    "        val_samples_per_class=VAL_SAMPLE_SIZE,\n",
    "        random_seed=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_file, model_name, data_yaml, training_config, base_dir):\n",
    "    \"\"\"\n",
    "    Train the RT-DETR model and return training results.\n",
    "    Clears previous training runs for this model before starting.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Project directory\n",
    "    project_dir = os.path.join(base_dir, \"training_runs\")\n",
    "    os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "    # Clear previous training runs for this model\n",
    "    for folder in os.listdir(project_dir):\n",
    "        if folder.startswith(model_name):\n",
    "            old_run_path = os.path.join(project_dir, folder)\n",
    "            print(f\"Removing previous run: {folder}\")\n",
    "            shutil.rmtree(old_run_path)\n",
    "\n",
    "    # Load pretrained model\n",
    "    model = RTDETR(model_file)\n",
    "\n",
    "    run_name = f\"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    \n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    results = model.train(\n",
    "        data=data_yaml,\n",
    "        epochs=training_config[\"epochs\"],\n",
    "        imgsz=training_config[\"imgsz\"],\n",
    "        batch=training_config[\"batch\"],\n",
    "        lr0=training_config[\"lr0\"],\n",
    "        lrf=training_config[\"lrf\"],\n",
    "        momentum=training_config[\"momentum\"],\n",
    "        weight_decay=training_config[\"weight_decay\"],\n",
    "        workers=training_config[\"workers\"],\n",
    "        patience=training_config[\"patience\"],\n",
    "        cos_lr=training_config[\"cos_lr\"],\n",
    "        warmup_epochs=training_config.get(\"warmup_epochs\", 1),\n",
    "        warmup_momentum=training_config.get(\"warmup_momentum\", 0.8),\n",
    "        warmup_bias_lr=training_config.get(\"warmup_bias_lr\", 0.1),\n",
    "        project=project_dir,\n",
    "        name=run_name,\n",
    "        save=True,\n",
    "        plots=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Get best model path\n",
    "    best_model_path = os.path.join(project_dir, run_name, \"weights\", \"best.pt\")\n",
    "    \n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"best_model_path\": best_model_path,\n",
    "        \"training_time\": training_time,\n",
    "        \"run_dir\": os.path.join(project_dir, run_name),\n",
    "        \"results\": results,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training: RT-DETR-L\n",
      "============================================================\n",
      "Removing previous run: RT-DETR-L_20260131_105955\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/rtdetr-l.pt to 'rtdetr-l.pt': 100% ━━━━━━━━━━━━ 63.4MB 10.5MB/s 6.0s6.0s<0.1s2s\n",
      "New https://pypi.org/project/ultralytics/8.4.9 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\data_full.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.0001, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=RT-DETR-L_20260201_123232, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260201_123232, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=1, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "WARNING no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7312127  ultralytics.nn.modules.head.RTDETRDecoder    [5, [256, 256, 256]]          \n",
      "rt-detr-l summary: 465 layers, 32,816,351 parameters, 32,816,351 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 240.532.0 MB/s, size: 29.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\Train\\labels\\Basophil.cache... 10166 images, 11 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 10176/10176  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 208.461.2 MB/s, size: 34.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\val\\labels\\Basophil.cache... 4261 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 4261/4261  0.0s\n",
      "Plotting labels to C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260201_123232\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.0005), 226 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260201_123232\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K        1/3      3.38G      1.353      12.55      1.062         17        640: 0% ──────────── 0/2544  1.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K        1/3      3.61G     0.2749      1.027     0.1507          5        640: 100% ━━━━━━━━━━━━ 2544/2544 2.5it/s 17:05<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 533/533 7.8it/s 1:08<0.1ss\n",
      "                   all       4261       6074      0.849      0.787       0.81      0.747\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K        2/3      3.89G     0.2167     0.8562     0.0916         11        640: 0% ──────────── 0/2544  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K        2/3       3.9G     0.2117     0.4804    0.09988          9        640: 100% ━━━━━━━━━━━━ 2544/2544 2.6it/s 16:31<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 533/533 7.7it/s 1:09<0.1ss\n",
      "                   all       4261       6074      0.856      0.813      0.821      0.761\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K        3/3       3.9G     0.1853     0.4169    0.08086         10        640: 0% ──────────── 0/2544  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K        3/3       3.9G     0.1871     0.4271    0.08572         11        640: 100% ━━━━━━━━━━━━ 2544/2544 2.5it/s 16:39<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 533/533 7.8it/s 1:08<0.1ss\n",
      "                   all       4261       6074      0.865      0.837      0.845      0.796\n",
      "\n",
      "3 epochs completed in 0.897 hours.\n",
      "Optimizer stripped from C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260201_123232\\weights\\last.pt, 66.2MB\n",
      "Optimizer stripped from C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260201_123232\\weights\\best.pt, 66.2MB\n",
      "\n",
      "Validating C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260201_123232\\weights\\best.pt...\n",
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "rt-detr-l summary: 310 layers, 31,994,015 parameters, 0 gradients, 103.5 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 533/533 8.5it/s 1:03<0.1ss\n",
      "                   all       4261       6074      0.865      0.838      0.845      0.795\n",
      "              Basophil         71        137      0.911      0.676      0.792      0.665\n",
      "            Eosinophil        305        627      0.708      0.907        0.8      0.759\n",
      "            Lymphocyte       1017       1124      0.934      0.908       0.92      0.901\n",
      "              Monocyte        217        239      0.856      0.808      0.804      0.793\n",
      "            Neutrophil       2651       3947      0.916      0.889      0.909      0.859\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260201_123232\u001b[0m\n",
      "\n",
      "Training completed in 3382.3s\n",
      "Best model saved to: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260201_123232\\weights\\best.pt\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "training_result = train_model(\n",
    "    MODEL_FILE,\n",
    "    MODEL_NAME,\n",
    "    DATA_YAML,\n",
    "    TRAINING_CONFIG,\n",
    "    BASE_DIR\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining completed in {training_result['training_time']:.1f}s\")\n",
    "print(f\"Best model saved to: {training_result['best_model_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_path, images_dir, classes, id2label, \n",
    "                   conf_thresh=0.1, eval_per_class=100, random_seed=123):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model on the dataset.\n",
    "    \"\"\"\n",
    "    model = RTDETR(model_path)\n",
    "    \n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    inference_times = []\n",
    "    \n",
    "    for gt_class, gt_id in classes.items():\n",
    "        cls_dir = os.path.join(images_dir, gt_class)\n",
    "        files = [f for f in os.listdir(cls_dir) if f.lower().endswith(\".jpg\")]\n",
    "        \n",
    "        if len(files) > eval_per_class:\n",
    "            files = random.sample(files, eval_per_class)\n",
    "        \n",
    "        for fname in tqdm(files, desc=f\"Evaluating {gt_class}\", leave=False):\n",
    "            img_path = os.path.join(cls_dir, fname)\n",
    "            \n",
    "            start = time.time()\n",
    "            results = model(img_path, conf=conf_thresh, verbose=False)[0]\n",
    "            inference_times.append(time.time() - start)\n",
    "            \n",
    "            y_true.append(gt_id)\n",
    "            \n",
    "            if len(results.boxes) == 0:\n",
    "                y_pred.append(-1)\n",
    "            else:\n",
    "                best_idx = results.boxes.conf.argmax()\n",
    "                y_pred.append(int(results.boxes.cls[best_idx].cpu().item()))\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    valid = y_pred != -1\n",
    "    valid_count = np.sum(valid)\n",
    "    \n",
    "    if valid_count > 0:\n",
    "        accuracy = accuracy_score(y_true[valid], y_pred[valid])\n",
    "        cm = confusion_matrix(y_true[valid], y_pred[valid], labels=list(range(len(classes))))\n",
    "        report = classification_report(\n",
    "            y_true[valid], y_pred[valid],\n",
    "            target_names=list(classes.keys()),\n",
    "            labels=list(range(len(classes))),\n",
    "            zero_division=0,\n",
    "            output_dict=True\n",
    "        )\n",
    "    else:\n",
    "        accuracy = 0.0\n",
    "        cm = None\n",
    "        report = None\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"no_prediction_count\": len(y_true) - valid_count,\n",
    "        \"total_samples\": len(y_true),\n",
    "        \"confusion_matrix\": cm.tolist() if cm is not None else None,\n",
    "        \"classification_report\": report,\n",
    "        \"avg_inference_time\": np.mean(inference_times),\n",
    "        \"y_true\": y_true.tolist(),\n",
    "        \"y_pred\": y_pred.tolist(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: RT-DETR-L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Accuracy: 0.9640\n",
      "  Avg inference time: 44.37ms\n",
      "  No predictions: 0/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "CONF_THRESH = 0.1\n",
    "EVAL_PER_CLASS = 100\n",
    "\n",
    "print(f\"Evaluating: {MODEL_NAME}\")\n",
    "evaluation_result = evaluate_model(\n",
    "    model_path=training_result[\"best_model_path\"],\n",
    "    images_dir=IMAGES_DIR,\n",
    "    classes=CLASSES,\n",
    "    id2label=ID2LABEL,\n",
    "    conf_thresh=CONF_THRESH,\n",
    "    eval_per_class=EVAL_PER_CLASS,\n",
    ")\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Accuracy: {evaluation_result['accuracy']:.4f}\")\n",
    "print(f\"  Avg inference time: {evaluation_result['avg_inference_time']*1000:.2f}ms\")\n",
    "print(f\"  No predictions: {evaluation_result['no_prediction_count']}/{evaluation_result['total_samples']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RT-DETR-L Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Basophil       1.00      1.00      1.00       100\n",
      "  Eosinophil       1.00      0.97      0.98       100\n",
      "  Lymphocyte       0.90      0.96      0.93       100\n",
      "    Monocyte       1.00      0.89      0.94       100\n",
      "  Neutrophil       0.93      1.00      0.97       100\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.97      0.96      0.96       500\n",
      "weighted avg       0.97      0.96      0.96       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "if evaluation_result[\"classification_report\"] is not None:\n",
    "    y_true = np.array(evaluation_result[\"y_true\"])\n",
    "    y_pred = np.array(evaluation_result[\"y_pred\"])\n",
    "    valid = y_pred != -1\n",
    "    \n",
    "    print(f\"\\n--- {MODEL_NAME} Classification Report ---\")\n",
    "    print(classification_report(\n",
    "        y_true[valid],\n",
    "        y_pred[valid],\n",
    "        target_names=list(CLASSES.keys()),\n",
    "        labels=list(range(NUM_CLASSES)),\n",
    "        zero_division=0\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\results\\RT-DETR-L_results.json\n"
     ]
    }
   ],
   "source": [
    "# Prepare results for saving (convert numpy types to native Python)\n",
    "def convert_to_native(obj):\n",
    "    \"\"\"Convert numpy types to native Python types for JSON serialization.\"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.int64, np.int32, np.int16, np.int8)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.float64, np.float32, np.float16)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_native(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_native(i) for i in obj]\n",
    "    return obj\n",
    "\n",
    "results_to_save = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"backbone\": BACKBONE,\n",
    "    \"is_pretrained\": IS_PRETRAINED,\n",
    "    \"best_model_path\": training_result[\"best_model_path\"],\n",
    "    \"run_dir\": training_result[\"run_dir\"],\n",
    "    \"training_time_s\": float(training_result[\"training_time\"]),\n",
    "    \"training_config\": TRAINING_CONFIG,\n",
    "    \"accuracy\": float(evaluation_result[\"accuracy\"]),\n",
    "    \"avg_inference_time_ms\": float(evaluation_result[\"avg_inference_time\"]) * 1000,\n",
    "    \"no_prediction_count\": int(evaluation_result[\"no_prediction_count\"]),\n",
    "    \"total_samples\": int(evaluation_result[\"total_samples\"]),\n",
    "    \"confusion_matrix\": convert_to_native(evaluation_result[\"confusion_matrix\"]),\n",
    "    \"classification_report\": convert_to_native(evaluation_result[\"classification_report\"]),\n",
    "    \"y_true\": convert_to_native(evaluation_result[\"y_true\"]),\n",
    "    \"y_pred\": convert_to_native(evaluation_result[\"y_pred\"]),\n",
    "    \"classes\": CLASSES,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "results_file = os.path.join(RESULTS_DIR, f\"{MODEL_NAME}_results.json\")\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(results_to_save, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Model: RT-DETR-L (ResNet-50)\n",
      "Accuracy: 0.9640\n",
      "Inference Time: 44.37ms\n",
      "Training Time: 3382.3s\n",
      "\n",
      "Best model: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260201_123232\\weights\\best.pt\n",
      "Results JSON: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\results\\RT-DETR-L_results.json\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {MODEL_NAME} ({BACKBONE})\")\n",
    "print(f\"Accuracy: {evaluation_result['accuracy']:.4f}\")\n",
    "print(f\"Inference Time: {evaluation_result['avg_inference_time']*1000:.2f}ms\")\n",
    "print(f\"Training Time: {training_result['training_time']:.1f}s\")\n",
    "print(f\"\\nBest model: {training_result['best_model_path']}\")\n",
    "print(f\"Results JSON: {results_file}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
