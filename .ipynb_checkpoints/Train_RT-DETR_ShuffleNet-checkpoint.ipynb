{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RT-DETR ShuffleNet Training\n",
    "\n",
    "Training RT-DETR with ShuffleNetV2-Small backbone for WBC Classification on Raabin-WBC dataset.\n",
    "\n",
    "## Model Details\n",
    "- **Backbone**: ShuffleNetV2-Small\n",
    "- **Training**: From scratch (no pretrained weights)\n",
    "- **Dataset**: Raabin-WBC with 5 cell types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U ultralytics torch torchvision pillow tqdm scikit-learn seaborn timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Import common training utilities\n",
    "from training_utils import (\n",
    "    create_sampled_dataset,\n",
    "    create_full_dataset_config,\n",
    "    train_model,\n",
    "    evaluate_model,\n",
    "    save_results,\n",
    "    print_training_summary,\n",
    ")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\n",
      "Base directory: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\n",
      "Data root: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\n",
      "Found model YAML: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\rtdetr_shufflenetv2.yaml\n",
      "\n",
      "Using device: cuda\n",
      "Dataset mode: FULL DATASET\n",
      "Checkpoint directory: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\checkpoints\\RT-DETR-ShuffleNet\n",
      "  -> Found existing checkpoint: 2 epochs completed\n",
      "  -> Training will RESUME from epoch 3\n",
      "\n",
      "Training data: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\Train\\images\n",
      "Validation data: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\val\\images\n",
      "\n",
      "Model: RT-DETR-ShuffleNet (ShuffleNetV2-Small)\n",
      "Training mode: From scratch\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MODEL CONFIGURATION\n",
    "# =============================================================================\n",
    "MODEL_NAME = \"RT-DETR-ShuffleNet\"\n",
    "BACKBONE = \"ShuffleNetV2-Small\"\n",
    "IS_PRETRAINED = False  # Training from scratch\n",
    "\n",
    "# =============================================================================\n",
    "# BASE DIRECTORY\n",
    "# =============================================================================\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "BASE_DIR = os.path.join(NOTEBOOK_DIR, \"output\")\n",
    "\n",
    "# Dataset path (contains separate Train and val folders)\n",
    "DATA_ROOT = r\"C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\"\n",
    "\n",
    "# Custom model YAML path\n",
    "MODEL_YAML_PATH = os.path.join(NOTEBOOK_DIR, \"rtdetr_shufflenetv2.yaml\")\n",
    "\n",
    "print(f\"Notebook directory: {NOTEBOOK_DIR}\")\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "\n",
    "# Verify YAML file exists\n",
    "if os.path.exists(MODEL_YAML_PATH):\n",
    "    print(f\"Found model YAML: {MODEL_YAML_PATH}\")\n",
    "else:\n",
    "    print(f\"WARNING: Model YAML not found at: {MODEL_YAML_PATH}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SAMPLING CONFIGURATION\n",
    "# =============================================================================\n",
    "USE_FULL_DATASET = True  # Set to True to use ALL images, False for sampling\n",
    "\n",
    "# Sample sizes per class (only used when USE_FULL_DATASET=False)\n",
    "TRAIN_SAMPLE_SIZE = 100   # Number of training samples per class\n",
    "VAL_SAMPLE_SIZE = 20      # Number of validation samples per class\n",
    "\n",
    "# =============================================================================\n",
    "# CHECKPOINT CONFIGURATION (for resume training on full dataset)\n",
    "# =============================================================================\n",
    "# Checkpoint directory - persistent location for full dataset training\n",
    "CHECKPOINT_DIR = os.path.join(BASE_DIR, \"checkpoints\", MODEL_NAME)\n",
    "CHECKPOINT_MODEL_PATH = os.path.join(CHECKPOINT_DIR, \"last.pt\")\n",
    "CHECKPOINT_META_PATH = os.path.join(CHECKPOINT_DIR, \"training_meta.json\")\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Data paths (separate train and validation directories)\n",
    "TRAIN_IMAGES_DIR = os.path.join(DATA_ROOT, \"Train\", \"images\")\n",
    "TRAIN_LABELS_DIR = os.path.join(DATA_ROOT, \"Train\", \"labels\")\n",
    "VAL_IMAGES_DIR = os.path.join(DATA_ROOT, \"val\", \"images\")\n",
    "VAL_LABELS_DIR = os.path.join(DATA_ROOT, \"val\", \"labels\")\n",
    "\n",
    "# For evaluation (uses training images by default)\n",
    "IMAGES_DIR = TRAIN_IMAGES_DIR\n",
    "\n",
    "# Output directories\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"results\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Class definitions\n",
    "CLASSES = {\n",
    "    \"Basophil\": 0,\n",
    "    \"Eosinophil\": 1,\n",
    "    \"Lymphocyte\": 2,\n",
    "    \"Monocyte\": 3,\n",
    "    \"Neutrophil\": 4\n",
    "}\n",
    "ID2LABEL = {v: k for k, v in CLASSES.items()}\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "print(f\"\\nUsing device: {DEVICE}\")\n",
    "if USE_FULL_DATASET:\n",
    "    print(f\"Dataset mode: FULL DATASET\")\n",
    "    print(f\"Checkpoint directory: {CHECKPOINT_DIR}\")\n",
    "    # Check for existing checkpoint\n",
    "    if os.path.exists(CHECKPOINT_MODEL_PATH) and os.path.exists(CHECKPOINT_META_PATH):\n",
    "        with open(CHECKPOINT_META_PATH, 'r') as f:\n",
    "            meta = json.load(f)\n",
    "        print(f\"  -> Found existing checkpoint: {meta['total_epochs']} epochs completed\")\n",
    "        print(f\"  -> Training will RESUME from epoch {meta['total_epochs'] + 1}\")\n",
    "    else:\n",
    "        print(f\"  -> No checkpoint found. Training will start from scratch.\")\n",
    "else:\n",
    "    print(f\"Dataset mode: SAMPLED (Train: {TRAIN_SAMPLE_SIZE}/class, Val: {VAL_SAMPLE_SIZE}/class)\")\n",
    "    print(f\"  -> Sampled mode: Always starts fresh (no resume)\")\n",
    "print(f\"\\nTraining data: {TRAIN_IMAGES_DIR}\")\n",
    "print(f\"Validation data: {VAL_IMAGES_DIR}\")\n",
    "print(f\"\\nModel: {MODEL_NAME} ({BACKBONE})\")\n",
    "print(f\"Training mode: {'Pretrained' if IS_PRETRAINED else 'From scratch'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "============================================================\n",
      "  epochs: 1\n",
      "  imgsz: 640\n",
      "  batch: 8\n",
      "  lr0: 0.0001\n",
      "  lrf: 0.01\n",
      "  momentum: 0.937\n",
      "  weight_decay: 0.0005\n",
      "  workers: 8\n",
      "  patience: 20\n",
      "  cos_lr: True\n",
      "  warmup_epochs: 3\n",
      "  warmup_momentum: 0.8\n",
      "  warmup_bias_lr: 0.01\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TRAINING HYPERPARAMETERS (FROM SCRATCH CONFIG)\n",
    "# =============================================================================\n",
    "# Training from scratch needs more epochs and lower learning rate\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    \"epochs\": 1,           \n",
    "    \"imgsz\": 640,\n",
    "    \"batch\": 8,\n",
    "    \"lr0\": 0.0001,          # Low LR for stability\n",
    "    \"lrf\": 0.01,\n",
    "    \"momentum\": 0.937,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"workers\": 8,\n",
    "    \"patience\": 20,\n",
    "    \"cos_lr\": True,\n",
    "    \"warmup_epochs\": 3,     # Gradual LR ramp-up for stability\n",
    "    \"warmup_momentum\": 0.8,\n",
    "    \"warmup_bias_lr\": 0.01,\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(\"=\"*60)\n",
    "for k, v in TRAINING_CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_sampled_dataset is imported from training_utils.py\n",
    "# See training_utils.py for the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FULL DATASET\n",
      "\n",
      "Training: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\Train\\images\n",
      "Validation: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\val\\images\n",
      "\n",
      "Data config: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\data_full.yaml\n"
     ]
    }
   ],
   "source": [
    "# Create data configuration\n",
    "if USE_FULL_DATASET:\n",
    "    print(\"Using FULL DATASET\\n\")\n",
    "    print(f\"Training: {TRAIN_IMAGES_DIR}\")\n",
    "    print(f\"Validation: {VAL_IMAGES_DIR}\")\n",
    "    \n",
    "    DATA_YAML = create_full_dataset_config(DATA_ROOT, BASE_DIR, NUM_CLASSES, ID2LABEL)\n",
    "    print(f\"\\nData config: {DATA_YAML}\")\n",
    "else:\n",
    "    print(f\"Creating SAMPLED dataset...\")\n",
    "    print(f\"  Train samples: {TRAIN_SAMPLE_SIZE} per class\")\n",
    "    print(f\"  Val samples: {VAL_SAMPLE_SIZE} per class\\n\")\n",
    "    \n",
    "    DATA_YAML = create_sampled_dataset(\n",
    "        DATA_ROOT, \n",
    "        BASE_DIR, \n",
    "        CLASSES, \n",
    "        train_samples_per_class=TRAIN_SAMPLE_SIZE,\n",
    "        val_samples_per_class=VAL_SAMPLE_SIZE,\n",
    "        random_seed=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model is imported from training_utils.py\n",
    "# See training_utils.py for the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training: RT-DETR-ShuffleNet\n",
      "============================================================\n",
      "\n",
      "*** RESUMING FROM CHECKPOINT ***\n",
      "  Previous epochs completed: 2\n",
      "  This session will train epochs: 3 to 3\n",
      "  Loading model from: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\checkpoints\\RT-DETR-ShuffleNet\\last.pt\n",
      "New https://pypi.org/project/ultralytics/8.4.9 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\data_full.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\checkpoints\\RT-DETR-ShuffleNet\\last.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=RT-DETR-ShuffleNet, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-ShuffleNet, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.01, warmup_epochs=0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       696  ultralytics.nn.modules.conv.Conv             [3, 24, 3, 2]                 \n",
      "  1                  -1  1       624  ultralytics.nn.modules.conv.Conv             [24, 24, 1, 1]                \n",
      "  2                  -1  1       264  ultralytics.nn.modules.conv.DWConv           [24, 24, 3, 2]                \n",
      "  3                  -1  1      1248  ultralytics.nn.modules.conv.Conv             [24, 48, 1, 1]                \n",
      "  4                  -1  3     39648  ultralytics.nn.modules.block.C2f             [48, 48, 3]                   \n",
      "  5                  -1  1      2400  ultralytics.nn.modules.conv.Conv             [48, 48, 1, 1]                \n",
      "  6                  -1  1       528  ultralytics.nn.modules.conv.DWConv           [48, 48, 3, 2]                \n",
      "  7                  -1  1      4800  ultralytics.nn.modules.conv.Conv             [48, 96, 1, 1]                \n",
      "  8                  -1  4    203904  ultralytics.nn.modules.block.C2f             [96, 96, 4]                   \n",
      "  9                  -1  1      9408  ultralytics.nn.modules.conv.Conv             [96, 96, 1, 1]                \n",
      " 10                  -1  1      1056  ultralytics.nn.modules.conv.DWConv           [96, 96, 3, 2]                \n",
      " 11                  -1  1     18816  ultralytics.nn.modules.conv.Conv             [96, 192, 1, 1]               \n",
      " 12                  -1  6   1182720  ultralytics.nn.modules.block.C2f             [192, 192, 6]                 \n",
      " 13                  -1  1     37248  ultralytics.nn.modules.conv.Conv             [192, 192, 1, 1]              \n",
      " 14                  -1  1      2112  ultralytics.nn.modules.conv.DWConv           [192, 192, 3, 2]              \n",
      " 15                  -1  1     74496  ultralytics.nn.modules.conv.Conv             [192, 384, 1, 1]              \n",
      " 16                  -1  3   2510592  ultralytics.nn.modules.block.C2f             [384, 384, 3]                 \n",
      " 17                  -1  1     98816  ultralytics.nn.modules.conv.Conv             [384, 256, 1, 1]              \n",
      " 18                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 19                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 20                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 21                  12  1     49664  ultralytics.nn.modules.conv.Conv             [192, 256, 1, 1]              \n",
      " 22            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 24                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 25                   8  1     25088  ultralytics.nn.modules.conv.Conv             [96, 256, 1, 1]               \n",
      " 26            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 29            [-1, 23]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 30                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 31                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 32            [-1, 19]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 33                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 34        [27, 30, 33]  1   3922820  ultralytics.nn.modules.head.RTDETRDecoder    [5, [256, 256, 256], 256, 300, 4, 8, 3]\n",
      "rtdetr_shufflenetv2 summary: 309 layers, 19,152,708 parameters, 19,152,708 gradients, 66.9 GFLOPs\n",
      "\n",
      "Transferred 683/683 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 244.144.3 MB/s, size: 29.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\Train\\labels\\Basophil.cache... 10166 images, 11 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 10176/10176  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 173.461.4 MB/s, size: 34.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\val\\labels\\Basophil.cache... 4261 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 4261/4261  0.0s\n",
      "Plotting labels to C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-ShuffleNet\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 106 weight(decay=0.0), 142 weight(decay=0.0005), 153 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-ShuffleNet\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K        1/1      4.02G     0.2217     0.7509    0.09512         29        640: 0% ──────────── 0/1272  1.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K        1/1      4.12G     0.3466     0.8546     0.1659         18        640: 100% ━━━━━━━━━━━━ 1272/1272 3.2it/s 6:42<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 267/267 5.4it/s 49.7s<0.2s\n",
      "                   all       4261       6074      0.471      0.493      0.431      0.397\n",
      "\n",
      "1 epochs completed in 0.127 hours.\n",
      "Optimizer stripped from C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-ShuffleNet\\weights\\last.pt, 38.7MB\n",
      "Optimizer stripped from C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-ShuffleNet\\weights\\best.pt, 38.7MB\n",
      "\n",
      "Validating C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-ShuffleNet\\weights\\best.pt...\n",
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "rtdetr_shufflenetv2 summary: 182 layers, 18,347,740 parameters, 0 gradients, 62.6 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 267/267 6.3it/s 42.5s<0.2s\n",
      "                   all       4261       6074      0.476      0.491      0.431      0.397\n",
      "              Basophil         71        137      0.572      0.109      0.152      0.132\n",
      "            Eosinophil        305        627      0.403      0.418      0.338      0.297\n",
      "            Lymphocyte       1017       1124        0.6      0.868      0.809      0.789\n",
      "              Monocyte        217        239      0.364      0.151      0.115        0.1\n",
      "            Neutrophil       2651       3947      0.441      0.907       0.74      0.668\n",
      "Speed: 0.3ms preprocess, 4.8ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-ShuffleNet\u001b[0m\n",
      "\n",
      "Checkpoint saved: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\checkpoints\\RT-DETR-ShuffleNet\\last.pt\n",
      "Metadata saved: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\checkpoints\\RT-DETR-ShuffleNet\\training_meta.json\n",
      "\n",
      "*** TOTAL EPOCHS COMPLETED: 3 ***\n",
      "\n",
      "Training completed in 587.0s\n",
      "Best model saved to: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-ShuffleNet\\weights\\best.pt\n",
      "\n",
      "Resumed from epoch 3\n",
      "Total epochs trained: 3\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "training_result = train_model(\n",
    "    model_source=MODEL_YAML_PATH,\n",
    "    model_name=MODEL_NAME,\n",
    "    data_yaml=DATA_YAML,\n",
    "    training_config=TRAINING_CONFIG,\n",
    "    base_dir=BASE_DIR,\n",
    "    use_full_dataset=USE_FULL_DATASET,\n",
    "    checkpoint_dir=CHECKPOINT_DIR if USE_FULL_DATASET else None,\n",
    "    default_warmup_epochs=3  # From scratch training needs more warmup\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining completed in {training_result['training_time']:.1f}s\")\n",
    "print(f\"Best model saved to: {training_result['best_model_path']}\")\n",
    "\n",
    "if training_result['resumed']:\n",
    "    print(f\"\\nResumed from epoch {training_result['previous_epochs'] + 1}\")\n",
    "print(f\"Total epochs trained: {training_result['total_epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model is imported from training_utils.py\n",
    "# See training_utils.py for the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: RT-DETR-ShuffleNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Accuracy: 0.4960\n",
      "  Avg inference time: 32.04ms\n",
      "  No predictions: 0/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "CONF_THRESH = 0.1\n",
    "EVAL_PER_CLASS = 100\n",
    "\n",
    "print(f\"Evaluating: {MODEL_NAME}\")\n",
    "evaluation_result = evaluate_model(\n",
    "    model_path=training_result[\"best_model_path\"],\n",
    "    images_dir=IMAGES_DIR,\n",
    "    classes=CLASSES,\n",
    "    id2label=ID2LABEL,\n",
    "    conf_thresh=CONF_THRESH,\n",
    "    eval_per_class=EVAL_PER_CLASS,\n",
    ")\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Accuracy: {evaluation_result['accuracy']:.4f}\")\n",
    "print(f\"  Avg inference time: {evaluation_result['avg_inference_time']*1000:.2f}ms\")\n",
    "print(f\"  No predictions: {evaluation_result['no_prediction_count']}/{evaluation_result['total_samples']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RT-DETR-ShuffleNet Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Basophil       1.00      0.08      0.15       100\n",
      "  Eosinophil       0.81      0.21      0.33       100\n",
      "  Lymphocyte       0.44      0.86      0.59       100\n",
      "    Monocyte       0.57      0.34      0.42       100\n",
      "  Neutrophil       0.47      0.99      0.63       100\n",
      "\n",
      "    accuracy                           0.50       500\n",
      "   macro avg       0.66      0.50      0.43       500\n",
      "weighted avg       0.66      0.50      0.43       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "if evaluation_result[\"classification_report\"] is not None:\n",
    "    y_true = np.array(evaluation_result[\"y_true\"])\n",
    "    y_pred = np.array(evaluation_result[\"y_pred\"])\n",
    "    valid = y_pred != -1\n",
    "    \n",
    "    print(f\"\\n--- {MODEL_NAME} Classification Report ---\")\n",
    "    print(classification_report(\n",
    "        y_true[valid],\n",
    "        y_pred[valid],\n",
    "        target_names=list(CLASSES.keys()),\n",
    "        labels=list(range(NUM_CLASSES)),\n",
    "        zero_division=0\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\results\\RT-DETR-ShuffleNet_results.json\n"
     ]
    }
   ],
   "source": [
    "# Save results to JSON\n",
    "results_file = save_results(\n",
    "    results_dir=RESULTS_DIR,\n",
    "    model_name=MODEL_NAME,\n",
    "    backbone=BACKBONE,\n",
    "    is_pretrained=IS_PRETRAINED,\n",
    "    training_result=training_result,\n",
    "    evaluation_result=evaluation_result,\n",
    "    training_config=TRAINING_CONFIG,\n",
    "    classes=CLASSES\n",
    ")\n",
    "\n",
    "print(f\"Results saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Model: RT-DETR-ShuffleNet (ShuffleNetV2-Small)\n",
      "Total Epochs: 3\n",
      "  (Resumed from epoch 3)\n",
      "Accuracy: 0.4960\n",
      "Inference Time: 32.04ms\n",
      "Training Time (this session): 587.0s\n",
      "\n",
      "Best model: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-ShuffleNet\\weights\\best.pt\n",
      "Checkpoint: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\checkpoints\\RT-DETR-ShuffleNet\\last.pt\n",
      "Results JSON: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\results\\RT-DETR-ShuffleNet_results.json\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Print training summary\n",
    "print_training_summary(\n",
    "    model_name=MODEL_NAME,\n",
    "    backbone=BACKBONE,\n",
    "    training_result=training_result,\n",
    "    evaluation_result=evaluation_result,\n",
    "    training_config=TRAINING_CONFIG,\n",
    "    checkpoint_model_path=CHECKPOINT_MODEL_PATH if USE_FULL_DATASET else None,\n",
    "    results_file=results_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
