{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RT-DETR-X Training\n",
    "\n",
    "Training RT-DETR-X with ResNet-101 backbone for WBC Classification on Raabin-WBC dataset.\n",
    "\n",
    "## Model Details\n",
    "- **Backbone**: ResNet-101\n",
    "- **Training**: Pretrained weights (fine-tuning)\n",
    "- **Dataset**: Raabin-WBC with 5 cell types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U ultralytics torch torchvision pillow tqdm scikit-learn seaborn timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Import common training utilities\n",
    "from training_utils import (\n",
    "    create_sampled_dataset,\n",
    "    create_full_dataset_config,\n",
    "    train_model,\n",
    "    evaluate_model,\n",
    "    save_results,\n",
    "    print_training_summary,\n",
    ")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\n",
      "Base directory: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\n",
      "Data root: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\n",
      "\n",
      "Using device: cuda\n",
      "Dataset mode: FULL DATASET\n",
      "Checkpoint directory: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\checkpoints\\RT-DETR-X\n",
      "  -> Found existing checkpoint: 1 epochs completed\n",
      "  -> Training will RESUME from epoch 2\n",
      "\n",
      "Training data: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\Train\\images\n",
      "Validation data: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\val\\images\n",
      "\n",
      "Model: RT-DETR-X (ResNet-101)\n",
      "Training mode: Pretrained (fine-tuning)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MODEL CONFIGURATION\n",
    "# =============================================================================\n",
    "MODEL_NAME = \"RT-DETR-X\"\n",
    "BACKBONE = \"ResNet-101\"\n",
    "IS_PRETRAINED = True  # Using pretrained weights\n",
    "\n",
    "# Pretrained model file\n",
    "MODEL_FILE = \"rtdetr-x.pt\"\n",
    "\n",
    "# =============================================================================\n",
    "# BASE DIRECTORY\n",
    "# =============================================================================\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "BASE_DIR = os.path.join(NOTEBOOK_DIR, \"output\")\n",
    "\n",
    "# Dataset path (contains separate Train and val folders)\n",
    "DATA_ROOT = r\"C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\"\n",
    "\n",
    "print(f\"Notebook directory: {NOTEBOOK_DIR}\")\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SAMPLING CONFIGURATION\n",
    "# =============================================================================\n",
    "USE_FULL_DATASET = True  # Set to True to use ALL images, False for sampling\n",
    "\n",
    "# Sample sizes per class (only used when USE_FULL_DATASET=False)\n",
    "TRAIN_SAMPLE_SIZE = 100   # Number of training samples per class\n",
    "VAL_SAMPLE_SIZE = 20      # Number of validation samples per class\n",
    "\n",
    "# =============================================================================\n",
    "# CHECKPOINT CONFIGURATION (for resume training on full dataset)\n",
    "# =============================================================================\n",
    "CHECKPOINT_DIR = os.path.join(BASE_DIR, \"checkpoints\", MODEL_NAME)\n",
    "CHECKPOINT_MODEL_PATH = os.path.join(CHECKPOINT_DIR, \"last.pt\")\n",
    "CHECKPOINT_META_PATH = os.path.join(CHECKPOINT_DIR, \"training_meta.json\")\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Data paths (separate train and validation directories)\n",
    "TRAIN_IMAGES_DIR = os.path.join(DATA_ROOT, \"Train\", \"images\")\n",
    "TRAIN_LABELS_DIR = os.path.join(DATA_ROOT, \"Train\", \"labels\")\n",
    "VAL_IMAGES_DIR = os.path.join(DATA_ROOT, \"val\", \"images\")\n",
    "VAL_LABELS_DIR = os.path.join(DATA_ROOT, \"val\", \"labels\")\n",
    "\n",
    "# For evaluation (uses training images by default)\n",
    "IMAGES_DIR = TRAIN_IMAGES_DIR\n",
    "\n",
    "# Output directories\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"results\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Class definitions\n",
    "CLASSES = {\n",
    "    \"Basophil\": 0,\n",
    "    \"Eosinophil\": 1,\n",
    "    \"Lymphocyte\": 2,\n",
    "    \"Monocyte\": 3,\n",
    "    \"Neutrophil\": 4\n",
    "}\n",
    "ID2LABEL = {v: k for k, v in CLASSES.items()}\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "print(f\"\\nUsing device: {DEVICE}\")\n",
    "if USE_FULL_DATASET:\n",
    "    print(f\"Dataset mode: FULL DATASET\")\n",
    "    print(f\"Checkpoint directory: {CHECKPOINT_DIR}\")\n",
    "    # Check for existing checkpoint\n",
    "    if os.path.exists(CHECKPOINT_MODEL_PATH) and os.path.exists(CHECKPOINT_META_PATH):\n",
    "        with open(CHECKPOINT_META_PATH, 'r') as f:\n",
    "            meta = json.load(f)\n",
    "        print(f\"  -> Found existing checkpoint: {meta['total_epochs']} epochs completed\")\n",
    "        print(f\"  -> Training will RESUME from epoch {meta['total_epochs'] + 1}\")\n",
    "    else:\n",
    "        print(f\"  -> No checkpoint found. Training will start from scratch.\")\n",
    "else:\n",
    "    print(f\"Dataset mode: SAMPLED (Train: {TRAIN_SAMPLE_SIZE}/class, Val: {VAL_SAMPLE_SIZE}/class)\")\n",
    "    print(f\"  -> Sampled mode: Always starts fresh (no resume)\")\n",
    "print(f\"\\nTraining data: {TRAIN_IMAGES_DIR}\")\n",
    "print(f\"Validation data: {VAL_IMAGES_DIR}\")\n",
    "print(f\"\\nModel: {MODEL_NAME} ({BACKBONE})\")\n",
    "print(f\"Training mode: {'Pretrained (fine-tuning)' if IS_PRETRAINED else 'From scratch'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration (OPTIMIZED FOR 8GB VRAM):\n",
      "============================================================\n",
      "  epochs: 2\n",
      "  imgsz: 512\n",
      "  batch: 3\n",
      "  lr0: 0.01\n",
      "  lrf: 0.0001\n",
      "  momentum: 0.937\n",
      "  weight_decay: 0.0005\n",
      "  workers: 4\n",
      "  patience: 15\n",
      "  cos_lr: True\n",
      "  warmup_epochs: 1\n",
      "  warmup_momentum: 0.8\n",
      "  warmup_bias_lr: 0.1\n",
      "  amp: True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TRAINING HYPERPARAMETERS (PRETRAINED CONFIG - OPTIMIZED FOR SPEED)\n",
    "# =============================================================================\n",
    "# Fewer epochs needed since backbone is already trained\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    \"epochs\": 2,\n",
    "    \"imgsz\": 512,           # Reduced from 640 for faster processing\n",
    "    \"batch\": 3,             # Increased from 4 (AMP enables larger batch)\n",
    "    \"lr0\": 0.01,            \n",
    "    \"lrf\": 0.0001,\n",
    "    \"momentum\": 0.937,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"workers\": 4,           # Reduced to lower RAM usage\n",
    "    \"patience\": 15,\n",
    "    \"cos_lr\": True,\n",
    "    \"warmup_epochs\": 1,\n",
    "    \"warmup_momentum\": 0.8,\n",
    "    \"warmup_bias_lr\": 0.1,\n",
    "    \"amp\": True,            # Mixed precision - enables larger batch & speeds up\n",
    "}\n",
    "\n",
    "print(\"Training Configuration (OPTIMIZED FOR 8GB VRAM):\")\n",
    "print(\"=\"*60)\n",
    "for k, v in TRAINING_CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_sampled_dataset is imported from training_utils.py\n",
    "# See training_utils.py for the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FULL DATASET\n",
      "\n",
      "Training: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\Train\\images\n",
      "Validation: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\val\\images\n",
      "\n",
      "Data config: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\data_full.yaml\n"
     ]
    }
   ],
   "source": [
    "# Create data configuration\n",
    "if USE_FULL_DATASET:\n",
    "    print(\"Using FULL DATASET\\n\")\n",
    "    print(f\"Training: {TRAIN_IMAGES_DIR}\")\n",
    "    print(f\"Validation: {VAL_IMAGES_DIR}\")\n",
    "    \n",
    "    DATA_YAML = create_full_dataset_config(DATA_ROOT, BASE_DIR, NUM_CLASSES, ID2LABEL)\n",
    "    print(f\"\\nData config: {DATA_YAML}\")\n",
    "else:\n",
    "    print(f\"Creating SAMPLED dataset...\")\n",
    "    print(f\"  Train samples: {TRAIN_SAMPLE_SIZE} per class\")\n",
    "    print(f\"  Val samples: {VAL_SAMPLE_SIZE} per class\\n\")\n",
    "    \n",
    "    DATA_YAML = create_sampled_dataset(\n",
    "        DATA_ROOT, \n",
    "        BASE_DIR, \n",
    "        CLASSES, \n",
    "        train_samples_per_class=TRAIN_SAMPLE_SIZE,\n",
    "        val_samples_per_class=VAL_SAMPLE_SIZE,\n",
    "        random_seed=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model is imported from training_utils.py\n",
    "# See training_utils.py for the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training: RT-DETR-X\n",
      "============================================================\n",
      "\n",
      "*** RESUMING FROM CHECKPOINT ***\n",
      "  Previous epochs completed: 3\n",
      "  This session will train epochs: 4 to 5\n",
      "  Loading model from: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\checkpoints\\RT-DETR-X\\last.pt\n",
      "New https://pypi.org/project/ultralytics/8.4.11 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=3, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\data_full.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=2, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.0001, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\checkpoints\\RT-DETR-X\\last.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=RT-DETR-X, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-X, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "WARNING no model scale passed. Assuming scale='x'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25792  ultralytics.nn.modules.block.HGStem          [3, 32, 64]                   \n",
      "  1                  -1  6    259200  ultralytics.nn.modules.block.HGBlock         [64, 64, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6   1248256  ultralytics.nn.modules.block.HGBlock         [128, 128, 512, 3, 6]         \n",
      "  4                  -1  6   1788928  ultralytics.nn.modules.block.HGBlock         [512, 128, 512, 3, 6, False, True]\n",
      "  5                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  6                  -1  6   2079232  ultralytics.nn.modules.block.HGBlock         [512, 256, 1024, 5, 6, True, False]\n",
      "  7                  -1  6   2472448  ultralytics.nn.modules.block.HGBlock         [1024, 256, 1024, 5, 6, True, True]\n",
      "  8                  -1  6   2472448  ultralytics.nn.modules.block.HGBlock         [1024, 256, 1024, 5, 6, True, True]\n",
      "  9                  -1  6   2472448  ultralytics.nn.modules.block.HGBlock         [1024, 256, 1024, 5, 6, True, True]\n",
      " 10                  -1  6   2472448  ultralytics.nn.modules.block.HGBlock         [1024, 256, 1024, 5, 6, True, True]\n",
      " 11                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      " 12                  -1  6   8221696  ultralytics.nn.modules.block.HGBlock         [1024, 512, 2048, 5, 6, True, False]\n",
      " 13                  -1  6   9794560  ultralytics.nn.modules.block.HGBlock         [2048, 512, 2048, 5, 6, True, True]\n",
      " 14                  -1  1    787200  ultralytics.nn.modules.conv.Conv             [2048, 384, 1, 1, None, 1, 1, False]\n",
      " 15                  -1  1   2168192  ultralytics.nn.modules.transformer.AIFI      [384, 2048, 8]                \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.conv.Conv             [384, 384, 1, 1]              \n",
      " 17                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 18                  10  1    393984  ultralytics.nn.modules.conv.Conv             [1024, 384, 1, 1, None, 1, 1, False]\n",
      " 19            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  3   5019648  ultralytics.nn.modules.block.RepC3           [768, 384, 3]                 \n",
      " 21                  -1  1    148224  ultralytics.nn.modules.conv.Conv             [384, 384, 1, 1]              \n",
      " 22                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 23                   4  1    197376  ultralytics.nn.modules.conv.Conv             [512, 384, 1, 1, None, 1, 1, False]\n",
      " 24            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 25                  -1  3   5019648  ultralytics.nn.modules.block.RepC3           [768, 384, 3]                 \n",
      " 26                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 27            [-1, 21]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 28                  -1  3   5019648  ultralytics.nn.modules.block.RepC3           [768, 384, 3]                 \n",
      " 29                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 30            [-1, 16]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 31                  -1  3   5019648  ultralytics.nn.modules.block.RepC3           [768, 384, 3]                 \n",
      " 32        [25, 28, 31]  1   7410431  ultralytics.nn.modules.head.RTDETRDecoder    [5, [384, 384, 384]]          \n",
      "rt-detr-x summary: 583 layers, 67,313,727 parameters, 67,313,727 gradients, 232.4 GFLOPs\n",
      "\n",
      "Transferred 1241/1241 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 241.946.9 MB/s, size: 31.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\Train\\labels\\Basophil.cache... 10166 images, 11 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 10176/10176  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 138.765.0 MB/s, size: 34.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\val\\labels\\Basophil.cache... 4261 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 4261/4261  0.0s\n",
      "Plotting labels to C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-X\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 193 weight(decay=0.0), 256 weight(decay=0.0004921875), 276 bias(decay=0.0)\n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mC:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-X\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K        1/2      2.94G    0.06309     0.1672    0.03227         12        512: 0% ──────────── 0/3392  0.7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K        1/2      3.55G     0.2123     0.5358     0.1007         10        512: 100% ━━━━━━━━━━━━ 3392/3392 2.4it/s 23:52<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 711/711 8.8it/s 1:21<0.1ss\n",
      "                   all       4261       6074      0.663      0.781      0.738      0.689\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K        2/2      3.92G     0.5234     0.5698     0.3346          6        512: 0% ──────────── 0/3392  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K        2/2      3.93G     0.1962     0.4719    0.09124         14        512: 100% ━━━━━━━━━━━━ 3392/3392 2.4it/s 23:40<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 711/711 8.8it/s 1:21<0.1ss\n",
      "                   all       4261       6074      0.831      0.673      0.638      0.599\n",
      "\n",
      "2 epochs completed in 0.839 hours.\n",
      "Optimizer stripped from C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-X\\weights\\last.pt, 135.4MB\n",
      "Optimizer stripped from C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-X\\weights\\best.pt, 135.4MB\n",
      "\n",
      "Validating C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-X\\weights\\best.pt...\n",
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "rt-detr-x summary: 378 layers, 65,477,711 parameters, 0 gradients, 222.5 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 711/711 10.5it/s 1:08<0.1ss\n",
      "                   all       4261       6074      0.662      0.781      0.736      0.687\n",
      "              Basophil         71        137      0.182       0.73      0.507      0.428\n",
      "            Eosinophil        305        627        0.7      0.624      0.638      0.581\n",
      "            Lymphocyte       1017       1124      0.937      0.888      0.893      0.879\n",
      "              Monocyte        217        239       0.59      0.833       0.78      0.758\n",
      "            Neutrophil       2651       3947      0.903      0.832      0.862      0.791\n",
      "Speed: 0.2ms preprocess, 11.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-X\u001b[0m\n",
      "\n",
      "Checkpoint saved: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\checkpoints\\RT-DETR-X\\last.pt\n",
      "Metadata saved: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\checkpoints\\RT-DETR-X\\training_meta.json\n",
      "\n",
      "*** TOTAL EPOCHS COMPLETED: 5 ***\n",
      "\n",
      "Training completed in 3152.4s\n",
      "Best model saved to: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-X\\weights\\best.pt\n",
      "\n",
      "Resumed from epoch 4\n",
      "Total epochs trained: 5\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "training_result = train_model(\n",
    "    model_source=MODEL_FILE,\n",
    "    model_name=MODEL_NAME,\n",
    "    data_yaml=DATA_YAML,\n",
    "    training_config=TRAINING_CONFIG,\n",
    "    base_dir=BASE_DIR,\n",
    "    use_full_dataset=USE_FULL_DATASET,\n",
    "    checkpoint_dir=CHECKPOINT_DIR if USE_FULL_DATASET else None,\n",
    "    default_warmup_epochs=1  # Pretrained model needs less warmup\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining completed in {training_result['training_time']:.1f}s\")\n",
    "print(f\"Best model saved to: {training_result['best_model_path']}\")\n",
    "\n",
    "if training_result['resumed']:\n",
    "    print(f\"\\nResumed from epoch {training_result['previous_epochs'] + 1}\")\n",
    "print(f\"Total epochs trained: {training_result['total_epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model is imported from training_utils.py\n",
    "# See training_utils.py for the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: RT-DETR-X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Accuracy: 0.9140\n",
      "  Avg inference time: 48.73ms\n",
      "  No predictions: 0/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "CONF_THRESH = 0.1\n",
    "EVAL_PER_CLASS = 100\n",
    "\n",
    "print(f\"Evaluating: {MODEL_NAME}\")\n",
    "evaluation_result = evaluate_model(\n",
    "    model_path=training_result[\"best_model_path\"],\n",
    "    images_dir=IMAGES_DIR,\n",
    "    classes=CLASSES,\n",
    "    id2label=ID2LABEL,\n",
    "    conf_thresh=CONF_THRESH,\n",
    "    eval_per_class=EVAL_PER_CLASS,\n",
    ")\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Accuracy: {evaluation_result['accuracy']:.4f}\")\n",
    "print(f\"  Avg inference time: {evaluation_result['avg_inference_time']*1000:.2f}ms\")\n",
    "print(f\"  No predictions: {evaluation_result['no_prediction_count']}/{evaluation_result['total_samples']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RT-DETR-X Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Basophil       1.00      1.00      1.00       100\n",
      "  Eosinophil       0.97      0.72      0.83       100\n",
      "  Lymphocyte       0.96      0.90      0.93       100\n",
      "    Monocyte       0.76      0.97      0.85       100\n",
      "  Neutrophil       0.93      0.98      0.96       100\n",
      "\n",
      "    accuracy                           0.91       500\n",
      "   macro avg       0.93      0.91      0.91       500\n",
      "weighted avg       0.93      0.91      0.91       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "if evaluation_result[\"classification_report\"] is not None:\n",
    "    y_true = np.array(evaluation_result[\"y_true\"])\n",
    "    y_pred = np.array(evaluation_result[\"y_pred\"])\n",
    "    valid = y_pred != -1\n",
    "    \n",
    "    print(f\"\\n--- {MODEL_NAME} Classification Report ---\")\n",
    "    print(classification_report(\n",
    "        y_true[valid],\n",
    "        y_pred[valid],\n",
    "        target_names=list(CLASSES.keys()),\n",
    "        labels=list(range(NUM_CLASSES)),\n",
    "        zero_division=0\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\results\\RT-DETR-X_results.json\n"
     ]
    }
   ],
   "source": [
    "# Save results to JSON\n",
    "results_file = save_results(\n",
    "    results_dir=RESULTS_DIR,\n",
    "    model_name=MODEL_NAME,\n",
    "    backbone=BACKBONE,\n",
    "    is_pretrained=IS_PRETRAINED,\n",
    "    training_result=training_result,\n",
    "    evaluation_result=evaluation_result,\n",
    "    training_config=TRAINING_CONFIG,\n",
    "    classes=CLASSES\n",
    ")\n",
    "\n",
    "print(f\"Results saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Model: RT-DETR-X (ResNet-101)\n",
      "Total Epochs: 5\n",
      "  (Resumed from epoch 4)\n",
      "Accuracy: 0.9140\n",
      "Inference Time: 48.73ms\n",
      "Training Time (this session): 3152.4s\n",
      "\n",
      "Best model: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-X\\weights\\best.pt\n",
      "Checkpoint: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\checkpoints\\RT-DETR-X\\last.pt\n",
      "Results JSON: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\results\\RT-DETR-X_results.json\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Print training summary\n",
    "print_training_summary(\n",
    "    model_name=MODEL_NAME,\n",
    "    backbone=BACKBONE,\n",
    "    training_result=training_result,\n",
    "    evaluation_result=evaluation_result,\n",
    "    training_config=TRAINING_CONFIG,\n",
    "    checkpoint_model_path=CHECKPOINT_MODEL_PATH if USE_FULL_DATASET else None,\n",
    "    results_file=results_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
