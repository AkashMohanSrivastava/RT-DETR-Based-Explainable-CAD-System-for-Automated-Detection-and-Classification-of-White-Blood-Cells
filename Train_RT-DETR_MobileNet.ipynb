{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RT-DETR MobileNet Training\n",
    "\n",
    "Training RT-DETR with MobileNetV3-Small backbone for WBC Classification on Raabin-WBC dataset.\n",
    "\n",
    "## Model Details\n",
    "- **Backbone**: MobileNetV3-Small\n",
    "- **Training**: From scratch (no pretrained weights)\n",
    "- **Dataset**: Raabin-WBC with 5 cell types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U ultralytics torch torchvision pillow tqdm scikit-learn seaborn timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import yaml\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ultralytics import RTDETR\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\n",
      "Base directory: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\n",
      "Data root: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\n",
      "Found model YAML: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\rtdetr_mobilenetv3.yaml\n",
      "\n",
      "Using device: cuda\n",
      "Samples per class: 100\n",
      "\n",
      "Model: RT-DETR-MobileNet (MobileNetV3-Small)\n",
      "Training mode: From scratch\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MODEL CONFIGURATION\n",
    "# =============================================================================\n",
    "MODEL_NAME = \"RT-DETR-MobileNet\"\n",
    "BACKBONE = \"MobileNetV3-Small\"\n",
    "IS_PRETRAINED = False  # Training from scratch\n",
    "\n",
    "# =============================================================================\n",
    "# BASE DIRECTORY\n",
    "# =============================================================================\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "BASE_DIR = os.path.join(NOTEBOOK_DIR, \"output\")\n",
    "\n",
    "# Dataset path\n",
    "DATA_ROOT = r\"C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\"\n",
    "\n",
    "# Custom model YAML path\n",
    "MODEL_YAML_PATH = os.path.join(NOTEBOOK_DIR, \"rtdetr_mobilenetv3.yaml\")\n",
    "\n",
    "print(f\"Notebook directory: {NOTEBOOK_DIR}\")\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "\n",
    "# Verify YAML file exists\n",
    "if os.path.exists(MODEL_YAML_PATH):\n",
    "    print(f\"Found model YAML: {MODEL_YAML_PATH}\")\n",
    "else:\n",
    "    print(f\"WARNING: Model YAML not found at: {MODEL_YAML_PATH}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SAMPLING CONFIGURATION\n",
    "# =============================================================================\n",
    "SAMPLES_PER_CLASS = 100  # Set to None for full dataset\n",
    "\n",
    "# Data paths\n",
    "IMAGES_DIR = os.path.join(DATA_ROOT, \"Train\", \"images\")\n",
    "LABELS_DIR = os.path.join(DATA_ROOT, \"Train\", \"labels\")\n",
    "\n",
    "# Output directories\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"results\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Class definitions\n",
    "CLASSES = {\n",
    "    \"Basophil\": 0,\n",
    "    \"Eosinophil\": 1,\n",
    "    \"Lymphocyte\": 2,\n",
    "    \"Monocyte\": 3,\n",
    "    \"Neutrophil\": 4\n",
    "}\n",
    "ID2LABEL = {v: k for k, v in CLASSES.items()}\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "print(f\"\\nUsing device: {DEVICE}\")\n",
    "print(f\"Samples per class: {SAMPLES_PER_CLASS if SAMPLES_PER_CLASS else 'ALL'}\")\n",
    "print(f\"\\nModel: {MODEL_NAME} ({BACKBONE})\")\n",
    "print(f\"Training mode: {'Pretrained' if IS_PRETRAINED else 'From scratch'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "============================================================\n",
      "  epochs: 20\n",
      "  imgsz: 640\n",
      "  batch: 8\n",
      "  lr0: 0.0001\n",
      "  lrf: 0.01\n",
      "  momentum: 0.937\n",
      "  weight_decay: 0.0005\n",
      "  workers: 8\n",
      "  patience: 20\n",
      "  cos_lr: True\n",
      "  warmup_epochs: 3\n",
      "  warmup_momentum: 0.8\n",
      "  warmup_bias_lr: 0.01\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TRAINING HYPERPARAMETERS (FROM SCRATCH CONFIG)\n",
    "# =============================================================================\n",
    "# Training from scratch needs more epochs and lower learning rate\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    \"epochs\": 20,           \n",
    "    \"imgsz\": 640,\n",
    "    \"batch\": 8,\n",
    "    \"lr0\": 0.0001,          # Low LR for stability\n",
    "    \"lrf\": 0.01,\n",
    "    \"momentum\": 0.937,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"workers\": 8,\n",
    "    \"patience\": 20,\n",
    "    \"cos_lr\": True,\n",
    "    \"warmup_epochs\": 3,     # Gradual LR ramp-up for stability\n",
    "    \"warmup_momentum\": 0.8,\n",
    "    \"warmup_bias_lr\": 0.01,\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(\"=\"*60)\n",
    "for k, v in TRAINING_CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_subset(data_root, base_dir, classes, samples_per_class=None, random_seed=42):\n",
    "    \"\"\"\n",
    "    Create a training subset with ZERO image duplication.\n",
    "    - Creates train.txt/val.txt pointing to original images\n",
    "    - Corrects class IDs in original label files (fixes the dataset)\n",
    "    - No image files created in output folder\n",
    "    \"\"\"\n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "    \n",
    "    # Define paths\n",
    "    subset_dir = os.path.join(base_dir, \"data_subset\")\n",
    "    \n",
    "    # Source paths\n",
    "    src_train_images = os.path.join(data_root, \"Train\", \"images\")\n",
    "    src_train_labels = os.path.join(data_root, \"Train\", \"labels\")\n",
    "    src_val_images = os.path.join(data_root, \"val\", \"images\")\n",
    "    src_val_labels = os.path.join(data_root, \"val\", \"labels\")\n",
    "    \n",
    "    # Clean up existing subset directory\n",
    "    if os.path.exists(subset_dir):\n",
    "        shutil.rmtree(subset_dir)\n",
    "    os.makedirs(subset_dir, exist_ok=True)\n",
    "    \n",
    "    # Lists to store image paths for txt files\n",
    "    train_image_paths = []\n",
    "    val_image_paths = []\n",
    "    labels_corrected = 0\n",
    "    \n",
    "    total_train = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    for cls_name, cls_id in classes.items():\n",
    "        # --- Training data ---\n",
    "        src_cls_images = os.path.join(src_train_images, cls_name)\n",
    "        src_cls_labels = os.path.join(src_train_labels, cls_name)\n",
    "        \n",
    "        if os.path.exists(src_cls_images):\n",
    "            image_files = [f for f in os.listdir(src_cls_images) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            if samples_per_class is not None and len(image_files) > samples_per_class:\n",
    "                image_files = random.sample(image_files, samples_per_class)\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                base_name = os.path.splitext(img_file)[0]\n",
    "                \n",
    "                # Store path to ORIGINAL image\n",
    "                original_img_path = os.path.join(src_cls_images, img_file)\n",
    "                train_image_paths.append(original_img_path)\n",
    "                \n",
    "                # Correct the ORIGINAL label file (fix class ID)\n",
    "                label_file = base_name + \".txt\"\n",
    "                label_path = os.path.join(src_cls_labels, label_file)\n",
    "                \n",
    "                if os.path.exists(label_path):\n",
    "                    with open(label_path, 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                    \n",
    "                    new_lines = []\n",
    "                    needs_correction = False\n",
    "                    for line in lines:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) > 1:\n",
    "                            if parts[0] != str(cls_id):\n",
    "                                needs_correction = True\n",
    "                                parts[0] = str(cls_id)\n",
    "                            new_lines.append(' '.join(parts) + '\\n')\n",
    "                    \n",
    "                    if needs_correction:\n",
    "                        with open(label_path, 'w') as f:\n",
    "                            f.writelines(new_lines)\n",
    "                        labels_corrected += 1\n",
    "            \n",
    "            total_train += len(image_files)\n",
    "            print(f\"  {cls_name} (class {cls_id}): {len(image_files)} training images\")\n",
    "        \n",
    "        # --- Validation data ---\n",
    "        src_cls_val_images = os.path.join(src_val_images, cls_name)\n",
    "        src_cls_val_labels = os.path.join(src_val_labels, cls_name)\n",
    "        \n",
    "        if os.path.exists(src_cls_val_images):\n",
    "            val_files = [f for f in os.listdir(src_cls_val_images) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            if samples_per_class is not None:\n",
    "                val_sample_size = min(len(val_files), max(20, samples_per_class // 5))\n",
    "                if len(val_files) > val_sample_size:\n",
    "                    val_files = random.sample(val_files, val_sample_size)\n",
    "            \n",
    "            for img_file in val_files:\n",
    "                base_name = os.path.splitext(img_file)[0]\n",
    "                \n",
    "                # Store path to ORIGINAL image\n",
    "                original_img_path = os.path.join(src_cls_val_images, img_file)\n",
    "                val_image_paths.append(original_img_path)\n",
    "                \n",
    "                # Correct the ORIGINAL label file\n",
    "                label_file = base_name + \".txt\"\n",
    "                label_path = os.path.join(src_cls_val_labels, label_file)\n",
    "                \n",
    "                if os.path.exists(label_path):\n",
    "                    with open(label_path, 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                    \n",
    "                    new_lines = []\n",
    "                    needs_correction = False\n",
    "                    for line in lines:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) > 1:\n",
    "                            if parts[0] != str(cls_id):\n",
    "                                needs_correction = True\n",
    "                                parts[0] = str(cls_id)\n",
    "                            new_lines.append(' '.join(parts) + '\\n')\n",
    "                    \n",
    "                    if needs_correction:\n",
    "                        with open(label_path, 'w') as f:\n",
    "                            f.writelines(new_lines)\n",
    "                        labels_corrected += 1\n",
    "            \n",
    "            total_val += len(val_files)\n",
    "    \n",
    "    # Write train.txt with paths to original images\n",
    "    train_txt_path = os.path.join(subset_dir, \"train.txt\")\n",
    "    with open(train_txt_path, 'w') as f:\n",
    "        for img_path in train_image_paths:\n",
    "            f.write(img_path + '\\n')\n",
    "    \n",
    "    # Write val.txt with paths to original images\n",
    "    val_txt_path = os.path.join(subset_dir, \"val.txt\")\n",
    "    with open(val_txt_path, 'w') as f:\n",
    "        for img_path in val_image_paths:\n",
    "            f.write(img_path + '\\n')\n",
    "    \n",
    "    # Create data.yaml pointing to txt files\n",
    "    data_yaml_path = os.path.join(subset_dir, \"data.yaml\")\n",
    "    data_config = {\n",
    "        'path': data_root,  # Base path for label lookup\n",
    "        'train': train_txt_path,  # Absolute path to train.txt\n",
    "        'val': val_txt_path,  # Absolute path to val.txt\n",
    "        'nc': len(classes),\n",
    "        'names': {v: k for k, v in classes.items()}\n",
    "    }\n",
    "    \n",
    "    with open(data_yaml_path, 'w') as f:\n",
    "        yaml.dump(data_config, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"\\nSubset created:\")\n",
    "    print(f\"  Total training images: {total_train}\")\n",
    "    print(f\"  Total validation images: {total_val}\")\n",
    "    print(f\"  Labels corrected: {labels_corrected}\")\n",
    "    print(f\"  Data config: {data_yaml_path}\")\n",
    "    print(f\"  NO image files copied - using original dataset directly!\")\n",
    "    \n",
    "    return data_yaml_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training subset with 100 images per class...\n",
      "\n",
      "  Basophil (class 0): 100 training images\n",
      "  Eosinophil (class 1): 100 training images\n",
      "  Lymphocyte (class 2): 100 training images\n",
      "  Monocyte (class 3): 100 training images\n",
      "  Neutrophil (class 4): 100 training images\n",
      "\n",
      "Subset created:\n",
      "  Total training images: 500\n",
      "  Total validation images: 100\n",
      "  Labels corrected: 0\n",
      "  Data config: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\data_subset\\data.yaml\n",
      "  NO image files copied - using original dataset directly!\n"
     ]
    }
   ],
   "source": [
    "# Create training subset\n",
    "print(f\"Creating training subset with {SAMPLES_PER_CLASS if SAMPLES_PER_CLASS else 'ALL'} images per class...\\n\")\n",
    "DATA_YAML = create_training_subset(\n",
    "    DATA_ROOT, \n",
    "    BASE_DIR, \n",
    "    CLASSES, \n",
    "    samples_per_class=SAMPLES_PER_CLASS,\n",
    "    random_seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_yaml_path, model_name, data_yaml, training_config, base_dir):\n",
    "    \"\"\"\n",
    "    Train the RT-DETR model and return training results.\n",
    "    Clears previous training runs for this model before starting.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Project directory\n",
    "    project_dir = os.path.join(base_dir, \"training_runs\")\n",
    "    os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "    # Clear previous training runs for this model\n",
    "    for folder in os.listdir(project_dir):\n",
    "        if folder.startswith(model_name):\n",
    "            old_run_path = os.path.join(project_dir, folder)\n",
    "            print(f\"Removing previous run: {folder}\")\n",
    "            shutil.rmtree(old_run_path)\n",
    "\n",
    "    # Load model from YAML\n",
    "    model = RTDETR(model_yaml_path)\n",
    "\n",
    "    run_name = f\"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    \n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    results = model.train(\n",
    "        data=data_yaml,\n",
    "        epochs=training_config[\"epochs\"],\n",
    "        imgsz=training_config[\"imgsz\"],\n",
    "        batch=training_config[\"batch\"],\n",
    "        lr0=training_config[\"lr0\"],\n",
    "        lrf=training_config[\"lrf\"],\n",
    "        momentum=training_config[\"momentum\"],\n",
    "        weight_decay=training_config[\"weight_decay\"],\n",
    "        workers=training_config[\"workers\"],\n",
    "        patience=training_config[\"patience\"],\n",
    "        cos_lr=training_config[\"cos_lr\"],\n",
    "        warmup_epochs=training_config.get(\"warmup_epochs\", 3),\n",
    "        warmup_momentum=training_config.get(\"warmup_momentum\", 0.8),\n",
    "        warmup_bias_lr=training_config.get(\"warmup_bias_lr\", 0.1),\n",
    "        project=project_dir,\n",
    "        name=run_name,\n",
    "        save=True,\n",
    "        plots=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Get best model path\n",
    "    best_model_path = os.path.join(project_dir, run_name, \"weights\", \"best.pt\")\n",
    "    \n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"best_model_path\": best_model_path,\n",
    "        \"training_time\": training_time,\n",
    "        \"run_dir\": os.path.join(project_dir, run_name),\n",
    "        \"results\": results,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training: RT-DETR-MobileNet\n",
      "============================================================\n",
      "Removing previous run: RT-DETR-MobileNet_20260131_111033\n",
      "New https://pypi.org/project/ultralytics/8.4.9 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\data_subset\\data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\rtdetr_mobilenetv3.yaml, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=RT-DETR-MobileNet_20260131_111816, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet_20260131_111816, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.01, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1       176  ultralytics.nn.modules.conv.DWConv           [16, 16, 3, 1]                \n",
      "  2                  -1  1       288  ultralytics.nn.modules.conv.Conv             [16, 16, 1, 1]                \n",
      "  3                  -1  1      1152  ultralytics.nn.modules.conv.Conv             [16, 64, 1, 1]                \n",
      "  4                  -1  1       704  ultralytics.nn.modules.conv.DWConv           [64, 64, 3, 2]                \n",
      "  5                  -1  1      1584  ultralytics.nn.modules.conv.Conv             [64, 24, 1, 1]                \n",
      "  6                  -1  1      1872  ultralytics.nn.modules.conv.Conv             [24, 72, 1, 1]                \n",
      "  7                  -1  1       792  ultralytics.nn.modules.conv.DWConv           [72, 72, 3, 1]                \n",
      "  8                  -1  1      1776  ultralytics.nn.modules.conv.Conv             [72, 24, 1, 1]                \n",
      "  9                  -1  1      1872  ultralytics.nn.modules.conv.Conv             [24, 72, 1, 1]                \n",
      " 10                  -1  1      1944  ultralytics.nn.modules.conv.DWConv           [72, 72, 5, 2]                \n",
      " 11                  -1  1      2960  ultralytics.nn.modules.conv.Conv             [72, 40, 1, 1]                \n",
      " 12                  -1  2     19520  ultralytics.nn.modules.block.C2f             [40, 40, 2]                   \n",
      " 13                  -1  1      5040  ultralytics.nn.modules.conv.Conv             [40, 120, 1, 1]               \n",
      " 14                  -1  1      3240  ultralytics.nn.modules.conv.DWConv           [120, 120, 5, 2]              \n",
      " 15                  -1  1      9760  ultralytics.nn.modules.conv.Conv             [120, 80, 1, 1]               \n",
      " 16                  -1  3    109600  ultralytics.nn.modules.block.C2f             [80, 80, 3]                   \n",
      " 17                  -1  1     19680  ultralytics.nn.modules.conv.Conv             [80, 240, 1, 1]               \n",
      " 18                  -1  1      6480  ultralytics.nn.modules.conv.DWConv           [240, 240, 5, 2]              \n",
      " 19                  -1  1     38720  ultralytics.nn.modules.conv.Conv             [240, 160, 1, 1]              \n",
      " 20                  -1  2    308480  ultralytics.nn.modules.block.C2f             [160, 160, 2]                 \n",
      " 21                  -1  1     41472  ultralytics.nn.modules.conv.Conv             [160, 256, 1, 1]              \n",
      " 22                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 23                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 24                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 25                  16  1     20992  ultralytics.nn.modules.conv.Conv             [80, 256, 1, 1]               \n",
      " 26            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 29                  12  1     10752  ultralytics.nn.modules.conv.Conv             [40, 256, 1, 1]               \n",
      " 30            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 31                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 32                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 33            [-1, 27]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 34                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 35                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 36            [-1, 23]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 37                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 38        [31, 34, 37]  1   3922820  ultralytics.nn.modules.head.RTDETRDecoder    [5, [256, 256, 256], 256, 300, 4, 8, 3]\n",
      "rtdetr_mobilenetv3 summary: 279 layers, 15,497,900 parameters, 15,497,900 gradients, 57.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 108.152.7 MB/s, size: 35.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\Train\\labels\\Basophil.cache... 500 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 500/500  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 54.05.0 MB/s, size: 27.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\val\\labels\\Basophil.cache... 100 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 100/100  0.0s\n",
      "Plotting labels to C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet_20260131_111816\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 91 weight(decay=0.0), 127 weight(decay=0.0005), 138 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet_20260131_111816\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       1/20      3.86G      2.017      14.08      1.725         36        640: 0% ──────────── 0/63  1.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       1/20      4.02G      1.556      6.339      1.247         11        640: 100% ━━━━━━━━━━━━ 63/63 2.8it/s 22.7s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 6.6it/s 1.1s0.2s\n",
      "                   all        100        155    0.00014      0.183   0.000455   0.000239\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       2/20      4.15G      1.588     0.4908      1.169         19        640: 0% ──────────── 0/63  0.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       2/20      4.23G      1.447     0.6751      1.229         10        640: 100% ━━━━━━━━━━━━ 63/63 3.1it/s 20.4s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.1it/s 1.0s0.2s\n",
      "                   all        100        155      7e-06      0.005   3.93e-06   7.87e-07\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       3/20      4.19G      1.472     0.5742      1.242         18        640: 0% ──────────── 0/63  0.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       3/20      4.27G      1.479     0.6304      1.286          8        640: 100% ━━━━━━━━━━━━ 63/63 3.1it/s 20.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.2it/s 1.0s0.2s\n",
      "                   all        100        155     0.0005      0.182    0.00046   0.000171\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       4/20      4.26G      1.174       1.13     0.8736         14        640: 0% ──────────── 0/63  0.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       4/20      4.35G      1.306     0.7751      1.027          7        640: 100% ━━━━━━━━━━━━ 63/63 3.2it/s 20.0s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.1it/s 1.0s0.2s\n",
      "                   all        100        155   2.67e-05       0.02   2.03e-05   3.11e-06\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       5/20      4.09G      1.086      1.041     0.7536         26        640: 0% ──────────── 0/63  0.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       5/20       4.2G      1.163     0.9185     0.8287         12        640: 100% ━━━━━━━━━━━━ 63/63 3.1it/s 20.0s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.0it/s 1.0s0.2s\n",
      "                   all        100        155   0.000481      0.268    0.00144   0.000392\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       6/20      4.15G      1.345     0.7453      1.179         16        640: 0% ──────────── 0/63  0.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       6/20      4.23G      1.167     0.8784     0.8139          8        640: 100% ━━━━━━━━━━━━ 63/63 3.1it/s 20.0s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.0it/s 1.0s0.2s\n",
      "                   all        100        155        0.2     0.0348   0.000136   3.69e-05\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       7/20      4.19G      1.179     0.7854     0.8009         26        640: 0% ──────────── 0/63  0.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       7/20      4.27G      1.114     0.9123     0.7893         10        640: 100% ━━━━━━━━━━━━ 63/63 3.2it/s 19.9s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.1it/s 1.0s0.2s\n",
      "                   all        100        155     0.0153      0.262     0.0264    0.00959\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       8/20      4.16G       1.16     0.7789     0.7537         19        640: 0% ──────────── 0/63  0.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       8/20      4.24G      1.059     0.9116     0.7175         11        640: 100% ━━━━━━━━━━━━ 63/63 3.1it/s 20.0s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.1it/s 1.0s0.2s\n",
      "                   all        100        155      0.215      0.205     0.0153    0.00572\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       9/20      4.16G      1.038     0.8212     0.6664         19        640: 0% ──────────── 0/63  0.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       9/20      4.24G      1.031     0.8463      0.652          8        640: 100% ━━━━━━━━━━━━ 63/63 3.2it/s 19.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.0it/s 1.0s0.2s\n",
      "                   all        100        155      0.409     0.0533    0.00476    0.00121\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      10/20      4.16G     0.9753     0.8583     0.7283         18        640: 0% ──────────── 0/63  0.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      10/20      4.24G      1.025     0.8343     0.6495          8        640: 100% ━━━━━━━━━━━━ 63/63 3.1it/s 20.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.1it/s 1.0s0.2s\n",
      "                   all        100        155      0.354      0.234      0.112      0.036\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      11/20      4.15G     0.7259      1.096     0.6092         11        640: 0% ──────────── 0/63  0.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      11/20      4.22G     0.7614       1.01       0.62          6        640: 100% ━━━━━━━━━━━━ 63/63 3.2it/s 19.9s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.1it/s 1.0s0.2s\n",
      "                   all        100        155      0.236      0.359      0.228      0.103\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      12/20      4.17G     0.7246      1.217     0.6448         11        640: 0% ──────────── 0/63  0.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      12/20      4.25G     0.7662     0.9803     0.6032          6        640: 100% ━━━━━━━━━━━━ 63/63 3.2it/s 19.6s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.1it/s 1.0s0.2s\n",
      "                   all        100        155       0.22      0.507      0.306      0.137\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      13/20      4.19G     0.5091      1.312     0.4238          9        640: 0% ──────────── 0/63  0.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      13/20      4.29G     0.7318     0.9448      0.604          9        640: 100% ━━━━━━━━━━━━ 63/63 3.2it/s 19.5s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.1it/s 1.0s0.2s\n",
      "                   all        100        155      0.353      0.382      0.266      0.141\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      14/20      4.15G     0.8083     0.9742     0.5343         12        640: 0% ──────────── 0/63  0.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      14/20      4.24G     0.7243     0.9168     0.5797          9        640: 100% ━━━━━━━━━━━━ 63/63 3.2it/s 19.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.1it/s 1.0s0.2s\n",
      "                   all        100        155      0.516      0.415      0.369      0.218\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      15/20      4.15G     0.5791     0.8574     0.4913          9        640: 0% ──────────── 0/63  0.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      15/20      4.23G     0.7014      0.896     0.5642          6        640: 100% ━━━━━━━━━━━━ 63/63 3.2it/s 19.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 6.9it/s 1.0s0.2s\n",
      "                   all        100        155       0.59      0.385      0.356      0.211\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      16/20      4.12G     0.9535     0.7596     0.4945         29        640: 0% ──────────── 0/63  0.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      16/20       4.2G      0.688     0.9042     0.5398         10        640: 100% ━━━━━━━━━━━━ 63/63 3.2it/s 19.9s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.0it/s 1.0s0.2s\n",
      "                   all        100        155      0.301      0.498      0.366      0.211\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      17/20      4.15G      0.564     0.9481     0.3706         12        640: 0% ──────────── 0/63  0.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      17/20      4.24G     0.6691     0.8693     0.5275          7        640: 100% ━━━━━━━━━━━━ 63/63 3.2it/s 19.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 6.8it/s 1.0s0.2s\n",
      "                   all        100        155      0.376      0.495      0.407      0.226\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      18/20      4.16G     0.7029     0.7915     0.4039         13        640: 0% ──────────── 0/63  0.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      18/20      4.24G     0.6702     0.8484     0.5607          5        640: 100% ━━━━━━━━━━━━ 63/63 3.2it/s 19.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.0it/s 1.0s0.2s\n",
      "                   all        100        155      0.371      0.534      0.402      0.224\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      19/20      4.15G     0.5787     0.7808     0.4961         11        640: 0% ──────────── 0/63  0.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      19/20      4.22G     0.6784     0.8678     0.5432          4        640: 100% ━━━━━━━━━━━━ 63/63 3.2it/s 19.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.1it/s 1.0s0.2s\n",
      "                   all        100        155      0.417      0.496      0.414       0.24\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      20/20      4.26G     0.7387     0.7161     0.4646         13        640: 0% ──────────── 0/63  0.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      20/20      4.35G     0.6863     0.8536     0.5269          4        640: 100% ━━━━━━━━━━━━ 63/63 3.2it/s 19.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 7.1it/s 1.0s0.2s\n",
      "                   all        100        155       0.44      0.504      0.429      0.248\n",
      "\n",
      "20 epochs completed in 0.131 hours.\n",
      "Optimizer stripped from C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet_20260131_111816\\weights\\last.pt, 31.4MB\n",
      "Optimizer stripped from C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet_20260131_111816\\weights\\best.pt, 31.4MB\n",
      "\n",
      "Validating C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet_20260131_111816\\weights\\best.pt...\n",
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "rtdetr_mobilenetv3 summary: 167 layers, 14,695,956 parameters, 0 gradients, 52.9 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.1it/s 1.4s0.2s\n",
      "                   all        100        155       0.44      0.509      0.431      0.249\n",
      "              Basophil         20         40      0.541      0.525      0.524      0.358\n",
      "            Eosinophil         20         37      0.283      0.297       0.14     0.0471\n",
      "            Lymphocyte         20         24        0.5      0.792      0.753      0.508\n",
      "              Monocyte         20         23      0.604      0.478       0.46      0.252\n",
      "            Neutrophil         20         31      0.274      0.452      0.277      0.082\n",
      "Speed: 0.4ms preprocess, 6.0ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet_20260131_111816\u001b[0m\n",
      "\n",
      "Training completed in 557.5s\n",
      "Best model saved to: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet_20260131_111816\\weights\\best.pt\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "training_result = train_model(\n",
    "    MODEL_YAML_PATH,\n",
    "    MODEL_NAME,\n",
    "    DATA_YAML,\n",
    "    TRAINING_CONFIG,\n",
    "    BASE_DIR\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining completed in {training_result['training_time']:.1f}s\")\n",
    "print(f\"Best model saved to: {training_result['best_model_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_path, images_dir, classes, id2label, \n",
    "                   conf_thresh=0.1, eval_per_class=100, random_seed=123):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model on the dataset.\n",
    "    \"\"\"\n",
    "    model = RTDETR(model_path)\n",
    "    \n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    inference_times = []\n",
    "    \n",
    "    for gt_class, gt_id in classes.items():\n",
    "        cls_dir = os.path.join(images_dir, gt_class)\n",
    "        files = [f for f in os.listdir(cls_dir) if f.lower().endswith(\".jpg\")]\n",
    "        \n",
    "        if len(files) > eval_per_class:\n",
    "            files = random.sample(files, eval_per_class)\n",
    "        \n",
    "        for fname in tqdm(files, desc=f\"Evaluating {gt_class}\", leave=False):\n",
    "            img_path = os.path.join(cls_dir, fname)\n",
    "            \n",
    "            start = time.time()\n",
    "            results = model(img_path, conf=conf_thresh, verbose=False)[0]\n",
    "            inference_times.append(time.time() - start)\n",
    "            \n",
    "            y_true.append(gt_id)\n",
    "            \n",
    "            if len(results.boxes) == 0:\n",
    "                y_pred.append(-1)\n",
    "            else:\n",
    "                best_idx = results.boxes.conf.argmax()\n",
    "                y_pred.append(int(results.boxes.cls[best_idx].cpu().item()))\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    valid = y_pred != -1\n",
    "    valid_count = np.sum(valid)\n",
    "    \n",
    "    if valid_count > 0:\n",
    "        accuracy = accuracy_score(y_true[valid], y_pred[valid])\n",
    "        cm = confusion_matrix(y_true[valid], y_pred[valid], labels=list(range(len(classes))))\n",
    "        report = classification_report(\n",
    "            y_true[valid], y_pred[valid],\n",
    "            target_names=list(classes.keys()),\n",
    "            labels=list(range(len(classes))),\n",
    "            zero_division=0,\n",
    "            output_dict=True\n",
    "        )\n",
    "    else:\n",
    "        accuracy = 0.0\n",
    "        cm = None\n",
    "        report = None\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"no_prediction_count\": len(y_true) - valid_count,\n",
    "        \"total_samples\": len(y_true),\n",
    "        \"confusion_matrix\": cm.tolist() if cm is not None else None,\n",
    "        \"classification_report\": report,\n",
    "        \"avg_inference_time\": np.mean(inference_times),\n",
    "        \"y_true\": y_true.tolist(),\n",
    "        \"y_pred\": y_pred.tolist(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: RT-DETR-MobileNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Accuracy: 0.6880\n",
      "  Avg inference time: 30.84ms\n",
      "  No predictions: 0/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "CONF_THRESH = 0.1\n",
    "EVAL_PER_CLASS = 100\n",
    "\n",
    "print(f\"Evaluating: {MODEL_NAME}\")\n",
    "evaluation_result = evaluate_model(\n",
    "    model_path=training_result[\"best_model_path\"],\n",
    "    images_dir=IMAGES_DIR,\n",
    "    classes=CLASSES,\n",
    "    id2label=ID2LABEL,\n",
    "    conf_thresh=CONF_THRESH,\n",
    "    eval_per_class=EVAL_PER_CLASS,\n",
    ")\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Accuracy: {evaluation_result['accuracy']:.4f}\")\n",
    "print(f\"  Avg inference time: {evaluation_result['avg_inference_time']*1000:.2f}ms\")\n",
    "print(f\"  No predictions: {evaluation_result['no_prediction_count']}/{evaluation_result['total_samples']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RT-DETR-MobileNet Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Basophil       0.81      0.94      0.87       100\n",
      "  Eosinophil       0.69      0.41      0.52       100\n",
      "  Lymphocyte       0.58      0.93      0.72       100\n",
      "    Monocyte       0.60      0.46      0.52       100\n",
      "  Neutrophil       0.79      0.70      0.74       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.69      0.69      0.67       500\n",
      "weighted avg       0.69      0.69      0.67       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "if evaluation_result[\"classification_report\"] is not None:\n",
    "    y_true = np.array(evaluation_result[\"y_true\"])\n",
    "    y_pred = np.array(evaluation_result[\"y_pred\"])\n",
    "    valid = y_pred != -1\n",
    "    \n",
    "    print(f\"\\n--- {MODEL_NAME} Classification Report ---\")\n",
    "    print(classification_report(\n",
    "        y_true[valid],\n",
    "        y_pred[valid],\n",
    "        target_names=list(CLASSES.keys()),\n",
    "        labels=list(range(NUM_CLASSES)),\n",
    "        zero_division=0\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\results\\RT-DETR-MobileNet_results.json\n"
     ]
    }
   ],
   "source": [
    "# Prepare results for saving (convert numpy types to native Python)\n",
    "def convert_to_native(obj):\n",
    "    \"\"\"Convert numpy types to native Python types for JSON serialization.\"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.int64, np.int32, np.int16, np.int8)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.float64, np.float32, np.float16)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_native(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_native(i) for i in obj]\n",
    "    return obj\n",
    "\n",
    "results_to_save = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"backbone\": BACKBONE,\n",
    "    \"is_pretrained\": IS_PRETRAINED,\n",
    "    \"best_model_path\": training_result[\"best_model_path\"],\n",
    "    \"run_dir\": training_result[\"run_dir\"],\n",
    "    \"training_time_s\": float(training_result[\"training_time\"]),\n",
    "    \"training_config\": TRAINING_CONFIG,\n",
    "    \"accuracy\": float(evaluation_result[\"accuracy\"]),\n",
    "    \"avg_inference_time_ms\": float(evaluation_result[\"avg_inference_time\"]) * 1000,\n",
    "    \"no_prediction_count\": int(evaluation_result[\"no_prediction_count\"]),\n",
    "    \"total_samples\": int(evaluation_result[\"total_samples\"]),\n",
    "    \"confusion_matrix\": convert_to_native(evaluation_result[\"confusion_matrix\"]),\n",
    "    \"classification_report\": convert_to_native(evaluation_result[\"classification_report\"]),\n",
    "    \"y_true\": convert_to_native(evaluation_result[\"y_true\"]),\n",
    "    \"y_pred\": convert_to_native(evaluation_result[\"y_pred\"]),\n",
    "    \"classes\": CLASSES,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "results_file = os.path.join(RESULTS_DIR, f\"{MODEL_NAME}_results.json\")\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(results_to_save, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Model: RT-DETR-MobileNet (MobileNetV3-Small)\n",
      "Accuracy: 0.6880\n",
      "Inference Time: 30.84ms\n",
      "Training Time: 557.5s\n",
      "\n",
      "Best model: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet_20260131_111816\\weights\\best.pt\n",
      "Results JSON: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\results\\RT-DETR-MobileNet_results.json\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {MODEL_NAME} ({BACKBONE})\")\n",
    "print(f\"Accuracy: {evaluation_result['accuracy']:.4f}\")\n",
    "print(f\"Inference Time: {evaluation_result['avg_inference_time']*1000:.2f}ms\")\n",
    "print(f\"Training Time: {training_result['training_time']:.1f}s\")\n",
    "print(f\"\\nBest model: {training_result['best_model_path']}\")\n",
    "print(f\"Results JSON: {results_file}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
