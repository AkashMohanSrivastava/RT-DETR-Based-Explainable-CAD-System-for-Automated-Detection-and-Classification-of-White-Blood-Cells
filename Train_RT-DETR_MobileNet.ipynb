{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RT-DETR MobileNet Training\n",
    "\n",
    "Training RT-DETR with MobileNetV3-Small backbone for WBC Classification on Raabin-WBC dataset.\n",
    "\n",
    "## Model Details\n",
    "- **Backbone**: MobileNetV3-Small\n",
    "- **Training**: From scratch (no pretrained weights)\n",
    "- **Dataset**: Raabin-WBC with 5 cell types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U ultralytics torch torchvision pillow tqdm scikit-learn seaborn timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Import common training utilities\n",
    "from training_utils import (\n",
    "    create_sampled_dataset,\n",
    "    create_full_dataset_config,\n",
    "    train_model,\n",
    "    evaluate_model,\n",
    "    save_results,\n",
    "    print_training_summary,\n",
    ")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\n",
      "Base directory: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\n",
      "Data root: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\n",
      "Found model YAML: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\rtdetr_mobilenetv3.yaml\n",
      "\n",
      "Using device: cuda\n",
      "Dataset mode: FULL DATASET\n",
      "Checkpoint directory: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\checkpoints\\RT-DETR-MobileNet\n",
      "  -> No checkpoint found. Training will start from scratch.\n",
      "\n",
      "Training data: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\Train\\images\n",
      "Validation data: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\val\\images\n",
      "\n",
      "Model: RT-DETR-MobileNet (MobileNetV3-Small)\n",
      "Training mode: From scratch\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MODEL CONFIGURATION\n",
    "# =============================================================================\n",
    "MODEL_NAME = \"RT-DETR-MobileNet\"\n",
    "BACKBONE = \"MobileNetV3-Small\"\n",
    "IS_PRETRAINED = False  # Training from scratch\n",
    "\n",
    "# =============================================================================\n",
    "# BASE DIRECTORY\n",
    "# =============================================================================\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "BASE_DIR = os.path.join(NOTEBOOK_DIR, \"output\")\n",
    "\n",
    "# Dataset path (contains separate Train and val folders)\n",
    "DATA_ROOT = r\"C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\"\n",
    "\n",
    "# Custom model YAML path\n",
    "MODEL_YAML_PATH = os.path.join(NOTEBOOK_DIR, \"rtdetr_mobilenetv3.yaml\")\n",
    "\n",
    "print(f\"Notebook directory: {NOTEBOOK_DIR}\")\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "\n",
    "# Verify YAML file exists\n",
    "if os.path.exists(MODEL_YAML_PATH):\n",
    "    print(f\"Found model YAML: {MODEL_YAML_PATH}\")\n",
    "else:\n",
    "    print(f\"WARNING: Model YAML not found at: {MODEL_YAML_PATH}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SAMPLING CONFIGURATION\n",
    "# =============================================================================\n",
    "USE_FULL_DATASET = True  # Set to True to use ALL images, False for sampling\n",
    "\n",
    "# Sample sizes per class (only used when USE_FULL_DATASET=False)\n",
    "TRAIN_SAMPLE_SIZE = 100   # Number of training samples per class\n",
    "VAL_SAMPLE_SIZE = 20      # Number of validation samples per class\n",
    "\n",
    "# =============================================================================\n",
    "# CHECKPOINT CONFIGURATION (for resume training on full dataset)\n",
    "# =============================================================================\n",
    "CHECKPOINT_DIR = os.path.join(BASE_DIR, \"checkpoints\", MODEL_NAME)\n",
    "CHECKPOINT_MODEL_PATH = os.path.join(CHECKPOINT_DIR, \"last.pt\")\n",
    "CHECKPOINT_META_PATH = os.path.join(CHECKPOINT_DIR, \"training_meta.json\")\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Data paths (separate train and validation directories)\n",
    "TRAIN_IMAGES_DIR = os.path.join(DATA_ROOT, \"Train\", \"images\")\n",
    "TRAIN_LABELS_DIR = os.path.join(DATA_ROOT, \"Train\", \"labels\")\n",
    "VAL_IMAGES_DIR = os.path.join(DATA_ROOT, \"val\", \"images\")\n",
    "VAL_LABELS_DIR = os.path.join(DATA_ROOT, \"val\", \"labels\")\n",
    "\n",
    "# For evaluation (uses training images by default)\n",
    "IMAGES_DIR = TRAIN_IMAGES_DIR\n",
    "\n",
    "# Output directories\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"results\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Class definitions\n",
    "CLASSES = {\n",
    "    \"Basophil\": 0,\n",
    "    \"Eosinophil\": 1,\n",
    "    \"Lymphocyte\": 2,\n",
    "    \"Monocyte\": 3,\n",
    "    \"Neutrophil\": 4\n",
    "}\n",
    "ID2LABEL = {v: k for k, v in CLASSES.items()}\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "print(f\"\\nUsing device: {DEVICE}\")\n",
    "if USE_FULL_DATASET:\n",
    "    print(f\"Dataset mode: FULL DATASET\")\n",
    "    print(f\"Checkpoint directory: {CHECKPOINT_DIR}\")\n",
    "    # Check for existing checkpoint\n",
    "    if os.path.exists(CHECKPOINT_MODEL_PATH) and os.path.exists(CHECKPOINT_META_PATH):\n",
    "        with open(CHECKPOINT_META_PATH, 'r') as f:\n",
    "            meta = json.load(f)\n",
    "        print(f\"  -> Found existing checkpoint: {meta['total_epochs']} epochs completed\")\n",
    "        print(f\"  -> Training will RESUME from epoch {meta['total_epochs'] + 1}\")\n",
    "    else:\n",
    "        print(f\"  -> No checkpoint found. Training will start from scratch.\")\n",
    "else:\n",
    "    print(f\"Dataset mode: SAMPLED (Train: {TRAIN_SAMPLE_SIZE}/class, Val: {VAL_SAMPLE_SIZE}/class)\")\n",
    "    print(f\"  -> Sampled mode: Always starts fresh (no resume)\")\n",
    "print(f\"\\nTraining data: {TRAIN_IMAGES_DIR}\")\n",
    "print(f\"Validation data: {VAL_IMAGES_DIR}\")\n",
    "print(f\"\\nModel: {MODEL_NAME} ({BACKBONE})\")\n",
    "print(f\"Training mode: {'Pretrained' if IS_PRETRAINED else 'From scratch'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration (OPTIMIZED FOR 8GB VRAM):\n",
      "============================================================\n",
      "  epochs: 1\n",
      "  imgsz: 512\n",
      "  batch: 12\n",
      "  lr0: 0.0001\n",
      "  lrf: 0.01\n",
      "  momentum: 0.937\n",
      "  weight_decay: 0.0005\n",
      "  workers: 4\n",
      "  patience: 20\n",
      "  cos_lr: True\n",
      "  warmup_epochs: 3\n",
      "  warmup_momentum: 0.8\n",
      "  warmup_bias_lr: 0.01\n",
      "  amp: True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TRAINING HYPERPARAMETERS (FROM SCRATCH CONFIG - OPTIMIZED FOR SPEED)\n",
    "# =============================================================================\n",
    "# Training from scratch needs more epochs and lower learning rate\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    \"epochs\": 1,\n",
    "    \"imgsz\": 512,           # Reduced from 640 for faster processing\n",
    "    \"batch\": 12,            # Balanced for 8GB VRAM\n",
    "    \"lr0\": 0.0001,          # Low LR for stability\n",
    "    \"lrf\": 0.01,\n",
    "    \"momentum\": 0.937,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"workers\": 4,           # Reduced to lower RAM usage\n",
    "    \"patience\": 20,\n",
    "    \"cos_lr\": True,\n",
    "    \"warmup_epochs\": 3,     # Gradual LR ramp-up for stability\n",
    "    \"warmup_momentum\": 0.8,\n",
    "    \"warmup_bias_lr\": 0.01,\n",
    "    \"amp\": True,            # Mixed precision - reduces VRAM usage & speeds up\n",
    "}\n",
    "\n",
    "print(\"Training Configuration (OPTIMIZED FOR 8GB VRAM):\")\n",
    "print(\"=\"*60)\n",
    "for k, v in TRAINING_CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_sampled_dataset is imported from training_utils.py\n",
    "# See training_utils.py for the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FULL DATASET\n",
      "\n",
      "Training: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\Train\\images\n",
      "Validation: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\val\\images\n",
      "\n",
      "Data config: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\data_full.yaml\n"
     ]
    }
   ],
   "source": [
    "# Create data configuration\n",
    "if USE_FULL_DATASET:\n",
    "    print(\"Using FULL DATASET\\n\")\n",
    "    print(f\"Training: {TRAIN_IMAGES_DIR}\")\n",
    "    print(f\"Validation: {VAL_IMAGES_DIR}\")\n",
    "    \n",
    "    DATA_YAML = create_full_dataset_config(DATA_ROOT, BASE_DIR, NUM_CLASSES, ID2LABEL)\n",
    "    print(f\"\\nData config: {DATA_YAML}\")\n",
    "else:\n",
    "    print(f\"Creating SAMPLED dataset...\")\n",
    "    print(f\"  Train samples: {TRAIN_SAMPLE_SIZE} per class\")\n",
    "    print(f\"  Val samples: {VAL_SAMPLE_SIZE} per class\\n\")\n",
    "    \n",
    "    DATA_YAML = create_sampled_dataset(\n",
    "        DATA_ROOT, \n",
    "        BASE_DIR, \n",
    "        CLASSES, \n",
    "        train_samples_per_class=TRAIN_SAMPLE_SIZE,\n",
    "        val_samples_per_class=VAL_SAMPLE_SIZE,\n",
    "        random_seed=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model is imported from training_utils.py\n",
    "# See training_utils.py for the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training: RT-DETR-MobileNet\n",
      "============================================================\n",
      "\n",
      "No checkpoint found. Starting fresh training.\n",
      "New https://pypi.org/project/ultralytics/8.4.10 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=12, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\data_full.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\rtdetr_mobilenetv3.yaml, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=RT-DETR-MobileNet, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.01, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1       176  ultralytics.nn.modules.conv.DWConv           [16, 16, 3, 1]                \n",
      "  2                  -1  1       288  ultralytics.nn.modules.conv.Conv             [16, 16, 1, 1]                \n",
      "  3                  -1  1      1152  ultralytics.nn.modules.conv.Conv             [16, 64, 1, 1]                \n",
      "  4                  -1  1       704  ultralytics.nn.modules.conv.DWConv           [64, 64, 3, 2]                \n",
      "  5                  -1  1      1584  ultralytics.nn.modules.conv.Conv             [64, 24, 1, 1]                \n",
      "  6                  -1  1      1872  ultralytics.nn.modules.conv.Conv             [24, 72, 1, 1]                \n",
      "  7                  -1  1       792  ultralytics.nn.modules.conv.DWConv           [72, 72, 3, 1]                \n",
      "  8                  -1  1      1776  ultralytics.nn.modules.conv.Conv             [72, 24, 1, 1]                \n",
      "  9                  -1  1      1872  ultralytics.nn.modules.conv.Conv             [24, 72, 1, 1]                \n",
      " 10                  -1  1      1944  ultralytics.nn.modules.conv.DWConv           [72, 72, 5, 2]                \n",
      " 11                  -1  1      2960  ultralytics.nn.modules.conv.Conv             [72, 40, 1, 1]                \n",
      " 12                  -1  1     11440  ultralytics.nn.modules.block.C2f             [40, 40, 1]                   \n",
      " 13                  -1  1      5040  ultralytics.nn.modules.conv.Conv             [40, 120, 1, 1]               \n",
      " 14                  -1  1      3240  ultralytics.nn.modules.conv.DWConv           [120, 120, 5, 2]              \n",
      " 15                  -1  1      9760  ultralytics.nn.modules.conv.Conv             [120, 80, 1, 1]               \n",
      " 16                  -1  2     77440  ultralytics.nn.modules.block.C2f             [80, 80, 2]                   \n",
      " 17                  -1  1     19680  ultralytics.nn.modules.conv.Conv             [80, 240, 1, 1]               \n",
      " 18                  -1  1      6480  ultralytics.nn.modules.conv.DWConv           [240, 240, 5, 2]              \n",
      " 19                  -1  1     38720  ultralytics.nn.modules.conv.Conv             [240, 160, 1, 1]              \n",
      " 20                  -1  1    180160  ultralytics.nn.modules.block.C2f             [160, 160, 1]                 \n",
      " 21                  -1  1     41472  ultralytics.nn.modules.conv.Conv             [160, 256, 1, 1]              \n",
      " 22                  -1  1    527104  ultralytics.nn.modules.transformer.AIFI      [256, 512, 4]                 \n",
      " 23                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 24                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 25                  16  1     20992  ultralytics.nn.modules.conv.Conv             [80, 256, 1, 1]               \n",
      " 26            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  2   1575936  ultralytics.nn.modules.block.RepC3           [512, 256, 2]                 \n",
      " 28                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 29                  12  1     10752  ultralytics.nn.modules.conv.Conv             [40, 256, 1, 1]               \n",
      " 30            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 31                  -1  2   1575936  ultralytics.nn.modules.block.RepC3           [512, 256, 2]                 \n",
      " 32                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 33            [-1, 27]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 34                  -1  2   1575936  ultralytics.nn.modules.block.RepC3           [512, 256, 2]                 \n",
      " 35                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 36            [-1, 23]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 37                  -1  2   1575936  ultralytics.nn.modules.block.RepC3           [512, 256, 2]                 \n",
      " 38        [31, 34, 37]  1   3922820  ultralytics.nn.modules.head.RTDETRDecoder    [5, [256, 256, 256], 256, 300, 4, 8, 3]\n",
      "rtdetr_mobilenetv3 summary: 243 layers, 12,441,148 parameters, 12,441,148 gradients, 43.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 218.566.8 MB/s, size: 29.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\Train\\labels\\Basophil.cache... 10166 images, 11 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 10176/10176  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 283.761.0 MB/s, size: 34.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\val\\labels\\Basophil.cache... 4261 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 4261/4261  0.0s\n",
      "Plotting labels to C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 77 weight(decay=0.0), 113 weight(decay=0.00046875), 124 bias(decay=0.0)\n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mC:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K        1/1      3.84G      1.697      35.97      1.131         37        512: 0% ──────────── 0/848  1.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K        1/1      4.19G     0.9078      2.152     0.5669         38        512: 100% ━━━━━━━━━━━━ 848/848 3.1it/s 4:32<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 178/178 4.7it/s 37.8s0.2ss\n",
      "                   all       4261       6074      0.354      0.299      0.329      0.264\n",
      "\n",
      "1 epochs completed in 0.087 hours.\n",
      "Optimizer stripped from C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet\\weights\\last.pt, 25.2MB\n",
      "Optimizer stripped from C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet\\weights\\best.pt, 25.2MB\n",
      "\n",
      "Validating C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet\\weights\\best.pt...\n",
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "rtdetr_mobilenetv3 summary: 157 layers, 11,904,700 parameters, 0 gradients, 40.6 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 178/178 5.5it/s 32.5s0.2ss\n",
      "                   all       4261       6074      0.355        0.3      0.329      0.264\n",
      "              Basophil         71        137          0          0          0          0\n",
      "            Eosinophil        305        627          0          0     0.0588     0.0372\n",
      "            Lymphocyte       1017       1124      0.563      0.844      0.753      0.671\n",
      "              Monocyte        217        239      0.706     0.0335      0.269      0.199\n",
      "            Neutrophil       2651       3947      0.505      0.623      0.565      0.414\n",
      "Speed: 0.2ms preprocess, 2.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet\u001b[0m\n",
      "\n",
      "Checkpoint saved: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\checkpoints\\RT-DETR-MobileNet\\last.pt\n",
      "Metadata saved: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\checkpoints\\RT-DETR-MobileNet\\training_meta.json\n",
      "\n",
      "*** TOTAL EPOCHS COMPLETED: 1 ***\n",
      "\n",
      "Training completed in 401.0s\n",
      "Best model saved to: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet\\weights\\best.pt\n",
      "Total epochs trained: 1\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "training_result = train_model(\n",
    "    model_source=MODEL_YAML_PATH,\n",
    "    model_name=MODEL_NAME,\n",
    "    data_yaml=DATA_YAML,\n",
    "    training_config=TRAINING_CONFIG,\n",
    "    base_dir=BASE_DIR,\n",
    "    use_full_dataset=USE_FULL_DATASET,\n",
    "    checkpoint_dir=CHECKPOINT_DIR if USE_FULL_DATASET else None,\n",
    "    default_warmup_epochs=3  # From scratch training needs more warmup\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining completed in {training_result['training_time']:.1f}s\")\n",
    "print(f\"Best model saved to: {training_result['best_model_path']}\")\n",
    "\n",
    "if training_result['resumed']:\n",
    "    print(f\"\\nResumed from epoch {training_result['previous_epochs'] + 1}\")\n",
    "print(f\"Total epochs trained: {training_result['total_epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model is imported from training_utils.py\n",
    "# See training_utils.py for the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: RT-DETR-MobileNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Accuracy: 0.4280\n",
      "  Avg inference time: 25.38ms\n",
      "  No predictions: 0/500\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "CONF_THRESH = 0.1\n",
    "EVAL_PER_CLASS = 100\n",
    "\n",
    "print(f\"Evaluating: {MODEL_NAME}\")\n",
    "evaluation_result = evaluate_model(\n",
    "    model_path=training_result[\"best_model_path\"],\n",
    "    images_dir=IMAGES_DIR,\n",
    "    classes=CLASSES,\n",
    "    id2label=ID2LABEL,\n",
    "    conf_thresh=CONF_THRESH,\n",
    "    eval_per_class=EVAL_PER_CLASS,\n",
    ")\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Accuracy: {evaluation_result['accuracy']:.4f}\")\n",
    "print(f\"  Avg inference time: {evaluation_result['avg_inference_time']*1000:.2f}ms\")\n",
    "print(f\"  No predictions: {evaluation_result['no_prediction_count']}/{evaluation_result['total_samples']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RT-DETR-MobileNet Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Basophil       0.00      0.00      0.00       100\n",
      "  Eosinophil       0.00      0.00      0.00       100\n",
      "  Lymphocyte       0.36      0.92      0.52       100\n",
      "    Monocyte       0.55      0.22      0.31       100\n",
      "  Neutrophil       0.48      1.00      0.65       100\n",
      "\n",
      "    accuracy                           0.43       500\n",
      "   macro avg       0.28      0.43      0.30       500\n",
      "weighted avg       0.28      0.43      0.30       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "if evaluation_result[\"classification_report\"] is not None:\n",
    "    y_true = np.array(evaluation_result[\"y_true\"])\n",
    "    y_pred = np.array(evaluation_result[\"y_pred\"])\n",
    "    valid = y_pred != -1\n",
    "    \n",
    "    print(f\"\\n--- {MODEL_NAME} Classification Report ---\")\n",
    "    print(classification_report(\n",
    "        y_true[valid],\n",
    "        y_pred[valid],\n",
    "        target_names=list(CLASSES.keys()),\n",
    "        labels=list(range(NUM_CLASSES)),\n",
    "        zero_division=0\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\results\\RT-DETR-MobileNet_results.json\n"
     ]
    }
   ],
   "source": [
    "# Save results to JSON\n",
    "results_file = save_results(\n",
    "    results_dir=RESULTS_DIR,\n",
    "    model_name=MODEL_NAME,\n",
    "    backbone=BACKBONE,\n",
    "    is_pretrained=IS_PRETRAINED,\n",
    "    training_result=training_result,\n",
    "    evaluation_result=evaluation_result,\n",
    "    training_config=TRAINING_CONFIG,\n",
    "    classes=CLASSES\n",
    ")\n",
    "\n",
    "print(f\"Results saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Model: RT-DETR-MobileNet (MobileNetV3-Small)\n",
      "Total Epochs: 1\n",
      "Accuracy: 0.4280\n",
      "Inference Time: 25.38ms\n",
      "Training Time (this session): 401.0s\n",
      "\n",
      "Best model: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-MobileNet\\weights\\best.pt\n",
      "Checkpoint: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\checkpoints\\RT-DETR-MobileNet\\last.pt\n",
      "Results JSON: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\results\\RT-DETR-MobileNet_results.json\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Print training summary\n",
    "print_training_summary(\n",
    "    model_name=MODEL_NAME,\n",
    "    backbone=BACKBONE,\n",
    "    training_result=training_result,\n",
    "    evaluation_result=evaluation_result,\n",
    "    training_config=TRAINING_CONFIG,\n",
    "    checkpoint_model_path=CHECKPOINT_MODEL_PATH if USE_FULL_DATASET else None,\n",
    "    results_file=results_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
