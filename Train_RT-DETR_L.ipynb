{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RT-DETR-L Training\n",
    "\n",
    "Training RT-DETR-L with ResNet-50 backbone for WBC Classification on Raabin-WBC dataset.\n",
    "\n",
    "## Model Details\n",
    "- **Backbone**: ResNet-50\n",
    "- **Training**: Pretrained weights (fine-tuning)\n",
    "- **Dataset**: Raabin-WBC with 5 cell types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U ultralytics torch torchvision pillow tqdm scikit-learn seaborn timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import yaml\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ultralytics import RTDETR\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\n",
      "Base directory: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\n",
      "Data root: C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\n",
      "\n",
      "Using device: cuda\n",
      "Samples per class: 100\n",
      "\n",
      "Model: RT-DETR-L (ResNet-50)\n",
      "Training mode: Pretrained (fine-tuning)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MODEL CONFIGURATION\n",
    "# =============================================================================\n",
    "MODEL_NAME = \"RT-DETR-L\"\n",
    "BACKBONE = \"ResNet-50\"\n",
    "IS_PRETRAINED = True  # Using pretrained weights\n",
    "\n",
    "# Pretrained model file\n",
    "MODEL_FILE = \"rtdetr-l.pt\"\n",
    "\n",
    "# =============================================================================\n",
    "# BASE DIRECTORY\n",
    "# =============================================================================\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "BASE_DIR = os.path.join(NOTEBOOK_DIR, \"output\")\n",
    "\n",
    "# Dataset path\n",
    "DATA_ROOT = r\"C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\"\n",
    "\n",
    "print(f\"Notebook directory: {NOTEBOOK_DIR}\")\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SAMPLING CONFIGURATION\n",
    "# =============================================================================\n",
    "SAMPLES_PER_CLASS = 100  # Set to None for full dataset\n",
    "\n",
    "# Data paths\n",
    "IMAGES_DIR = os.path.join(DATA_ROOT, \"Train\", \"images\")\n",
    "LABELS_DIR = os.path.join(DATA_ROOT, \"Train\", \"labels\")\n",
    "\n",
    "# Output directories\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"results\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Class definitions\n",
    "CLASSES = {\n",
    "    \"Basophil\": 0,\n",
    "    \"Eosinophil\": 1,\n",
    "    \"Lymphocyte\": 2,\n",
    "    \"Monocyte\": 3,\n",
    "    \"Neutrophil\": 4\n",
    "}\n",
    "ID2LABEL = {v: k for k, v in CLASSES.items()}\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "print(f\"\\nUsing device: {DEVICE}\")\n",
    "print(f\"Samples per class: {SAMPLES_PER_CLASS if SAMPLES_PER_CLASS else 'ALL'}\")\n",
    "print(f\"\\nModel: {MODEL_NAME} ({BACKBONE})\")\n",
    "print(f\"Training mode: {'Pretrained (fine-tuning)' if IS_PRETRAINED else 'From scratch'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration (Pretrained Fine-tuning):\n",
      "============================================================\n",
      "  epochs: 3\n",
      "  imgsz: 640\n",
      "  batch: 4\n",
      "  lr0: 0.01\n",
      "  lrf: 0.0001\n",
      "  momentum: 0.937\n",
      "  weight_decay: 0.0005\n",
      "  workers: 8\n",
      "  patience: 15\n",
      "  cos_lr: True\n",
      "  warmup_epochs: 1\n",
      "  warmup_momentum: 0.8\n",
      "  warmup_bias_lr: 0.1\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TRAINING HYPERPARAMETERS (PRETRAINED CONFIG)\n",
    "# =============================================================================\n",
    "# Fewer epochs needed since backbone is already trained\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    \"epochs\": 3,            \n",
    "    \"imgsz\": 640,\n",
    "    \"batch\": 4,\n",
    "    \"lr0\": 0.01,            \n",
    "    \"lrf\": 0.0001,\n",
    "    \"momentum\": 0.937,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"workers\": 8,\n",
    "    \"patience\": 15,\n",
    "    \"cos_lr\": True,\n",
    "    \"warmup_epochs\": 1,\n",
    "    \"warmup_momentum\": 0.8,\n",
    "    \"warmup_bias_lr\": 0.1,\n",
    "}\n",
    "\n",
    "print(\"Training Configuration (Pretrained Fine-tuning):\")\n",
    "print(\"=\"*60)\n",
    "for k, v in TRAINING_CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_subset(data_root, base_dir, classes, samples_per_class=None, random_seed=42):\n",
    "    \"\"\"\n",
    "    Create a training subset with ZERO image duplication.\n",
    "    - Creates train.txt/val.txt pointing to original images\n",
    "    - Corrects class IDs in original label files (fixes the dataset)\n",
    "    - No image files created in output folder\n",
    "    \"\"\"\n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "    \n",
    "    # Define paths\n",
    "    subset_dir = os.path.join(base_dir, \"data_subset\")\n",
    "    \n",
    "    # Source paths\n",
    "    src_train_images = os.path.join(data_root, \"Train\", \"images\")\n",
    "    src_train_labels = os.path.join(data_root, \"Train\", \"labels\")\n",
    "    src_val_images = os.path.join(data_root, \"val\", \"images\")\n",
    "    src_val_labels = os.path.join(data_root, \"val\", \"labels\")\n",
    "    \n",
    "    # Clean up existing subset directory\n",
    "    if os.path.exists(subset_dir):\n",
    "        shutil.rmtree(subset_dir)\n",
    "    os.makedirs(subset_dir, exist_ok=True)\n",
    "    \n",
    "    # Lists to store image paths for txt files\n",
    "    train_image_paths = []\n",
    "    val_image_paths = []\n",
    "    labels_corrected = 0\n",
    "    \n",
    "    total_train = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    for cls_name, cls_id in classes.items():\n",
    "        # --- Training data ---\n",
    "        src_cls_images = os.path.join(src_train_images, cls_name)\n",
    "        src_cls_labels = os.path.join(src_train_labels, cls_name)\n",
    "        \n",
    "        if os.path.exists(src_cls_images):\n",
    "            image_files = [f for f in os.listdir(src_cls_images) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            if samples_per_class is not None and len(image_files) > samples_per_class:\n",
    "                image_files = random.sample(image_files, samples_per_class)\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                base_name = os.path.splitext(img_file)[0]\n",
    "                \n",
    "                # Store path to ORIGINAL image\n",
    "                original_img_path = os.path.join(src_cls_images, img_file)\n",
    "                train_image_paths.append(original_img_path)\n",
    "                \n",
    "                # Correct the ORIGINAL label file (fix class ID)\n",
    "                label_file = base_name + \".txt\"\n",
    "                label_path = os.path.join(src_cls_labels, label_file)\n",
    "                \n",
    "                if os.path.exists(label_path):\n",
    "                    with open(label_path, 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                    \n",
    "                    new_lines = []\n",
    "                    needs_correction = False\n",
    "                    for line in lines:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) > 1:\n",
    "                            if parts[0] != str(cls_id):\n",
    "                                needs_correction = True\n",
    "                                parts[0] = str(cls_id)\n",
    "                            new_lines.append(' '.join(parts) + '\\n')\n",
    "                    \n",
    "                    if needs_correction:\n",
    "                        with open(label_path, 'w') as f:\n",
    "                            f.writelines(new_lines)\n",
    "                        labels_corrected += 1\n",
    "            \n",
    "            total_train += len(image_files)\n",
    "            print(f\"  {cls_name} (class {cls_id}): {len(image_files)} training images\")\n",
    "        \n",
    "        # --- Validation data ---\n",
    "        src_cls_val_images = os.path.join(src_val_images, cls_name)\n",
    "        src_cls_val_labels = os.path.join(src_val_labels, cls_name)\n",
    "        \n",
    "        if os.path.exists(src_cls_val_images):\n",
    "            val_files = [f for f in os.listdir(src_cls_val_images) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            if samples_per_class is not None:\n",
    "                val_sample_size = min(len(val_files), max(20, samples_per_class // 5))\n",
    "                if len(val_files) > val_sample_size:\n",
    "                    val_files = random.sample(val_files, val_sample_size)\n",
    "            \n",
    "            for img_file in val_files:\n",
    "                base_name = os.path.splitext(img_file)[0]\n",
    "                \n",
    "                # Store path to ORIGINAL image\n",
    "                original_img_path = os.path.join(src_cls_val_images, img_file)\n",
    "                val_image_paths.append(original_img_path)\n",
    "                \n",
    "                # Correct the ORIGINAL label file\n",
    "                label_file = base_name + \".txt\"\n",
    "                label_path = os.path.join(src_cls_val_labels, label_file)\n",
    "                \n",
    "                if os.path.exists(label_path):\n",
    "                    with open(label_path, 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                    \n",
    "                    new_lines = []\n",
    "                    needs_correction = False\n",
    "                    for line in lines:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) > 1:\n",
    "                            if parts[0] != str(cls_id):\n",
    "                                needs_correction = True\n",
    "                                parts[0] = str(cls_id)\n",
    "                            new_lines.append(' '.join(parts) + '\\n')\n",
    "                    \n",
    "                    if needs_correction:\n",
    "                        with open(label_path, 'w') as f:\n",
    "                            f.writelines(new_lines)\n",
    "                        labels_corrected += 1\n",
    "            \n",
    "            total_val += len(val_files)\n",
    "    \n",
    "    # Write train.txt with paths to original images\n",
    "    train_txt_path = os.path.join(subset_dir, \"train.txt\")\n",
    "    with open(train_txt_path, 'w') as f:\n",
    "        for img_path in train_image_paths:\n",
    "            f.write(img_path + '\\n')\n",
    "    \n",
    "    # Write val.txt with paths to original images\n",
    "    val_txt_path = os.path.join(subset_dir, \"val.txt\")\n",
    "    with open(val_txt_path, 'w') as f:\n",
    "        for img_path in val_image_paths:\n",
    "            f.write(img_path + '\\n')\n",
    "    \n",
    "    # Create data.yaml pointing to txt files\n",
    "    data_yaml_path = os.path.join(subset_dir, \"data.yaml\")\n",
    "    data_config = {\n",
    "        'path': data_root,  # Base path for label lookup\n",
    "        'train': train_txt_path,  # Absolute path to train.txt\n",
    "        'val': val_txt_path,  # Absolute path to val.txt\n",
    "        'nc': len(classes),\n",
    "        'names': {v: k for k, v in classes.items()}\n",
    "    }\n",
    "    \n",
    "    with open(data_yaml_path, 'w') as f:\n",
    "        yaml.dump(data_config, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"\\nSubset created:\")\n",
    "    print(f\"  Total training images: {total_train}\")\n",
    "    print(f\"  Total validation images: {total_val}\")\n",
    "    print(f\"  Labels corrected: {labels_corrected}\")\n",
    "    print(f\"  Data config: {data_yaml_path}\")\n",
    "    print(f\"  NO image files copied - using original dataset directly!\")\n",
    "    \n",
    "    return data_yaml_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training subset with 100 images per class...\n",
      "\n",
      "  Basophil (class 0): 100 training images\n",
      "  Eosinophil (class 1): 100 training images\n",
      "  Lymphocyte (class 2): 100 training images\n",
      "  Monocyte (class 3): 100 training images\n",
      "  Neutrophil (class 4): 100 training images\n",
      "\n",
      "Subset created:\n",
      "  Total training images: 500\n",
      "  Total validation images: 100\n",
      "  Labels corrected: 0\n",
      "  Data config: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\data_subset\\data.yaml\n",
      "  NO image files copied - using original dataset directly!\n"
     ]
    }
   ],
   "source": [
    "# Create training subset\n",
    "print(f\"Creating training subset with {SAMPLES_PER_CLASS if SAMPLES_PER_CLASS else 'ALL'} images per class...\\n\")\n",
    "DATA_YAML = create_training_subset(\n",
    "    DATA_ROOT, \n",
    "    BASE_DIR, \n",
    "    CLASSES, \n",
    "    samples_per_class=SAMPLES_PER_CLASS,\n",
    "    random_seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_file, model_name, data_yaml, training_config, base_dir):\n",
    "    \"\"\"\n",
    "    Train the RT-DETR model and return training results.\n",
    "    Clears previous training runs for this model before starting.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Project directory\n",
    "    project_dir = os.path.join(base_dir, \"training_runs\")\n",
    "    os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "    # Clear previous training runs for this model\n",
    "    for folder in os.listdir(project_dir):\n",
    "        if folder.startswith(model_name):\n",
    "            old_run_path = os.path.join(project_dir, folder)\n",
    "            print(f\"Removing previous run: {folder}\")\n",
    "            shutil.rmtree(old_run_path)\n",
    "\n",
    "    # Load pretrained model\n",
    "    model = RTDETR(model_file)\n",
    "\n",
    "    run_name = f\"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    \n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    results = model.train(\n",
    "        data=data_yaml,\n",
    "        epochs=training_config[\"epochs\"],\n",
    "        imgsz=training_config[\"imgsz\"],\n",
    "        batch=training_config[\"batch\"],\n",
    "        lr0=training_config[\"lr0\"],\n",
    "        lrf=training_config[\"lrf\"],\n",
    "        momentum=training_config[\"momentum\"],\n",
    "        weight_decay=training_config[\"weight_decay\"],\n",
    "        workers=training_config[\"workers\"],\n",
    "        patience=training_config[\"patience\"],\n",
    "        cos_lr=training_config[\"cos_lr\"],\n",
    "        warmup_epochs=training_config.get(\"warmup_epochs\", 1),\n",
    "        warmup_momentum=training_config.get(\"warmup_momentum\", 0.8),\n",
    "        warmup_bias_lr=training_config.get(\"warmup_bias_lr\", 0.1),\n",
    "        project=project_dir,\n",
    "        name=run_name,\n",
    "        save=True,\n",
    "        plots=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Get best model path\n",
    "    best_model_path = os.path.join(project_dir, run_name, \"weights\", \"best.pt\")\n",
    "    \n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"best_model_path\": best_model_path,\n",
    "        \"training_time\": training_time,\n",
    "        \"run_dir\": os.path.join(project_dir, run_name),\n",
    "        \"results\": results,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training: RT-DETR-L\n",
      "============================================================\n",
      "New https://pypi.org/project/ultralytics/8.4.9 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\data_subset\\data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.0001, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=RT-DETR-L_20260131_105955, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260131_105955, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=1, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "WARNING no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7312127  ultralytics.nn.modules.head.RTDETRDecoder    [5, [256, 256, 256]]          \n",
      "rt-detr-l summary: 465 layers, 32,816,351 parameters, 32,816,351 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 246.6119.1 MB/s, size: 35.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\Train\\labels\\Basophil.cache... 500 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 500/500  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 117.635.3 MB/s, size: 27.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\D drive\\mydata\\MSML\\DataSets\\Raabin_datsets_withlabels\\val\\labels\\Basophil.cache... 100 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 100/100  0.0s\n",
      "Plotting labels to C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260131_105955\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.0005), 226 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260131_105955\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K        1/3      3.42G      0.871      11.48     0.8034         17        640: 0% ──────────── 0/125  1.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K        1/3       3.6G     0.6263      5.737     0.4378         12        640: 100% ━━━━━━━━━━━━ 125/125 2.5it/s 49.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 8.1it/s 1.6s0.1s\n",
      "                   all        100        155      0.193      0.342      0.219      0.189\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K        2/3      3.88G     0.3795      1.299     0.1482         11        640: 0% ──────────── 0/125  0.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K        2/3      3.88G     0.3037      1.099     0.1573          8        640: 100% ━━━━━━━━━━━━ 125/125 2.6it/s 48.0s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 8.5it/s 1.5s0.1s\n",
      "                   all        100        155      0.367      0.388       0.32      0.287\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K        3/3      3.97G     0.3295     0.7725     0.2182         13        640: 0% ──────────── 0/125  0.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:96.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K        3/3      3.97G     0.2821      0.908     0.1509         12        640: 100% ━━━━━━━━━━━━ 125/125 2.6it/s 47.9s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 8.4it/s 1.5s0.1s\n",
      "                   all        100        155       0.58       0.57      0.467      0.414\n",
      "\n",
      "3 epochs completed in 0.043 hours.\n",
      "Optimizer stripped from C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260131_105955\\weights\\last.pt, 66.2MB\n",
      "Optimizer stripped from C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260131_105955\\weights\\best.pt, 66.2MB\n",
      "\n",
      "Validating C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260131_105955\\weights\\best.pt...\n",
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 8188MiB)\n",
      "rt-detr-l summary: 310 layers, 31,994,015 parameters, 0 gradients, 103.5 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 7.6it/s 1.7s0.1s\n",
      "                   all        100        155      0.579       0.57      0.468      0.415\n",
      "              Basophil         20         40      0.822       0.65      0.663      0.518\n",
      "            Eosinophil         20         37      0.359      0.027     0.0265     0.0121\n",
      "            Lymphocyte         20         24      0.458      0.792      0.399      0.383\n",
      "              Monocyte         20         23      0.825      0.609      0.705      0.687\n",
      "            Neutrophil         20         31      0.431      0.774      0.548      0.475\n",
      "Speed: 0.3ms preprocess, 12.4ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260131_105955\u001b[0m\n",
      "\n",
      "Training completed in 238.5s\n",
      "Best model saved to: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260131_105955\\weights\\best.pt\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "training_result = train_model(\n",
    "    MODEL_FILE,\n",
    "    MODEL_NAME,\n",
    "    DATA_YAML,\n",
    "    TRAINING_CONFIG,\n",
    "    BASE_DIR\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining completed in {training_result['training_time']:.1f}s\")\n",
    "print(f\"Best model saved to: {training_result['best_model_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_path, images_dir, classes, id2label, \n",
    "                   conf_thresh=0.1, eval_per_class=100, random_seed=123):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model on the dataset.\n",
    "    \"\"\"\n",
    "    model = RTDETR(model_path)\n",
    "    \n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    inference_times = []\n",
    "    \n",
    "    for gt_class, gt_id in classes.items():\n",
    "        cls_dir = os.path.join(images_dir, gt_class)\n",
    "        files = [f for f in os.listdir(cls_dir) if f.lower().endswith(\".jpg\")]\n",
    "        \n",
    "        if len(files) > eval_per_class:\n",
    "            files = random.sample(files, eval_per_class)\n",
    "        \n",
    "        for fname in tqdm(files, desc=f\"Evaluating {gt_class}\", leave=False):\n",
    "            img_path = os.path.join(cls_dir, fname)\n",
    "            \n",
    "            start = time.time()\n",
    "            results = model(img_path, conf=conf_thresh, verbose=False)[0]\n",
    "            inference_times.append(time.time() - start)\n",
    "            \n",
    "            y_true.append(gt_id)\n",
    "            \n",
    "            if len(results.boxes) == 0:\n",
    "                y_pred.append(-1)\n",
    "            else:\n",
    "                best_idx = results.boxes.conf.argmax()\n",
    "                y_pred.append(int(results.boxes.cls[best_idx].cpu().item()))\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    valid = y_pred != -1\n",
    "    valid_count = np.sum(valid)\n",
    "    \n",
    "    if valid_count > 0:\n",
    "        accuracy = accuracy_score(y_true[valid], y_pred[valid])\n",
    "        cm = confusion_matrix(y_true[valid], y_pred[valid], labels=list(range(len(classes))))\n",
    "        report = classification_report(\n",
    "            y_true[valid], y_pred[valid],\n",
    "            target_names=list(classes.keys()),\n",
    "            labels=list(range(len(classes))),\n",
    "            zero_division=0,\n",
    "            output_dict=True\n",
    "        )\n",
    "    else:\n",
    "        accuracy = 0.0\n",
    "        cm = None\n",
    "        report = None\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"no_prediction_count\": len(y_true) - valid_count,\n",
    "        \"total_samples\": len(y_true),\n",
    "        \"confusion_matrix\": cm.tolist() if cm is not None else None,\n",
    "        \"classification_report\": report,\n",
    "        \"avg_inference_time\": np.mean(inference_times),\n",
    "        \"y_true\": y_true.tolist(),\n",
    "        \"y_pred\": y_pred.tolist(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: RT-DETR-L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Accuracy: 0.6914\n",
      "  Avg inference time: 39.89ms\n",
      "  No predictions: 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "CONF_THRESH = 0.1\n",
    "EVAL_PER_CLASS = 100\n",
    "\n",
    "print(f\"Evaluating: {MODEL_NAME}\")\n",
    "evaluation_result = evaluate_model(\n",
    "    model_path=training_result[\"best_model_path\"],\n",
    "    images_dir=IMAGES_DIR,\n",
    "    classes=CLASSES,\n",
    "    id2label=ID2LABEL,\n",
    "    conf_thresh=CONF_THRESH,\n",
    "    eval_per_class=EVAL_PER_CLASS,\n",
    ")\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Accuracy: {evaluation_result['accuracy']:.4f}\")\n",
    "print(f\"  Avg inference time: {evaluation_result['avg_inference_time']*1000:.2f}ms\")\n",
    "print(f\"  No predictions: {evaluation_result['no_prediction_count']}/{evaluation_result['total_samples']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RT-DETR-L Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Basophil       0.73      1.00      0.84       100\n",
      "  Eosinophil       0.86      0.06      0.11       100\n",
      "  Lymphocyte       0.60      0.89      0.72        99\n",
      "    Monocyte       0.90      0.57      0.70       100\n",
      "  Neutrophil       0.64      0.94      0.76       100\n",
      "\n",
      "    accuracy                           0.69       499\n",
      "   macro avg       0.75      0.69      0.63       499\n",
      "weighted avg       0.75      0.69      0.63       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "if evaluation_result[\"classification_report\"] is not None:\n",
    "    y_true = np.array(evaluation_result[\"y_true\"])\n",
    "    y_pred = np.array(evaluation_result[\"y_pred\"])\n",
    "    valid = y_pred != -1\n",
    "    \n",
    "    print(f\"\\n--- {MODEL_NAME} Classification Report ---\")\n",
    "    print(classification_report(\n",
    "        y_true[valid],\n",
    "        y_pred[valid],\n",
    "        target_names=list(CLASSES.keys()),\n",
    "        labels=list(range(NUM_CLASSES)),\n",
    "        zero_division=0\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\results\\RT-DETR-L_results.json\n"
     ]
    }
   ],
   "source": [
    "# Prepare results for saving (convert numpy types to native Python)\n",
    "def convert_to_native(obj):\n",
    "    \"\"\"Convert numpy types to native Python types for JSON serialization.\"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.int64, np.int32, np.int16, np.int8)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.float64, np.float32, np.float16)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_native(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_native(i) for i in obj]\n",
    "    return obj\n",
    "\n",
    "results_to_save = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"backbone\": BACKBONE,\n",
    "    \"is_pretrained\": IS_PRETRAINED,\n",
    "    \"best_model_path\": training_result[\"best_model_path\"],\n",
    "    \"run_dir\": training_result[\"run_dir\"],\n",
    "    \"training_time_s\": float(training_result[\"training_time\"]),\n",
    "    \"training_config\": TRAINING_CONFIG,\n",
    "    \"accuracy\": float(evaluation_result[\"accuracy\"]),\n",
    "    \"avg_inference_time_ms\": float(evaluation_result[\"avg_inference_time\"]) * 1000,\n",
    "    \"no_prediction_count\": int(evaluation_result[\"no_prediction_count\"]),\n",
    "    \"total_samples\": int(evaluation_result[\"total_samples\"]),\n",
    "    \"confusion_matrix\": convert_to_native(evaluation_result[\"confusion_matrix\"]),\n",
    "    \"classification_report\": convert_to_native(evaluation_result[\"classification_report\"]),\n",
    "    \"y_true\": convert_to_native(evaluation_result[\"y_true\"]),\n",
    "    \"y_pred\": convert_to_native(evaluation_result[\"y_pred\"]),\n",
    "    \"classes\": CLASSES,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "results_file = os.path.join(RESULTS_DIR, f\"{MODEL_NAME}_results.json\")\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(results_to_save, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Model: RT-DETR-L (ResNet-50)\n",
      "Accuracy: 0.6914\n",
      "Inference Time: 39.89ms\n",
      "Training Time: 238.5s\n",
      "\n",
      "Best model: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\training_runs\\RT-DETR-L_20260131_105955\\weights\\best.pt\n",
      "Results JSON: C:\\D drive\\mydata\\MSML\\GitHub\\RT-DETR-Based-Explainable-CAD-System-for-Automated-Detection-and-Classification-of-White-Blood-Cells\\output\\results\\RT-DETR-L_results.json\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {MODEL_NAME} ({BACKBONE})\")\n",
    "print(f\"Accuracy: {evaluation_result['accuracy']:.4f}\")\n",
    "print(f\"Inference Time: {evaluation_result['avg_inference_time']*1000:.2f}ms\")\n",
    "print(f\"Training Time: {training_result['training_time']:.1f}s\")\n",
    "print(f\"\\nBest model: {training_result['best_model_path']}\")\n",
    "print(f\"Results JSON: {results_file}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
